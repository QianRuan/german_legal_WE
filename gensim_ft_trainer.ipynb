{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText \n",
    "from gensim.test.utils import datapath\n",
    "import time\n",
    "from gensim.test.utils import get_tmpfile\n",
    "import logging\n",
    "from gensim import utils\n",
    "from itertools import chain\n",
    "from gensim.utils import tokenize\n",
    "import smart_open\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\german_legal_WE'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogies = datapath(os.getcwd()+'\\\\german-legal-analogies.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## open the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the small legal corpus\n",
    "class MyIterSmall(object):\n",
    "    def __iter__(self):\n",
    "        path = datapath(os.getcwd()+'\\\\German_legal_corpora\\\\cleaned-small-legal-corpus.txt')\n",
    "        with smart_open.smart_open(path, 'r', encoding='utf-8') as fin:\n",
    "            for line in fin:\n",
    "                yield list(tokenize(line))\n",
    "#open the huge legal corpus\n",
    "class MyIterHuge(object):\n",
    "    def __iter__(self):\n",
    "        path = datapath(os.getcwd()+'\\\\German_legal_corpora\\\\cleaned-huge-legal-corpus.txt')\n",
    "        with smart_open.smart_open(path, 'r', encoding='utf-8') as fin:\n",
    "            for line in fin:\n",
    "                yield list(tokenize(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## train_fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fasttext(small,window,size,sg):\n",
    "    modelName='ft_s'+str(small)+'_w'+str(window)+'_d' +str(size)+'_sg' +str(sg)\n",
    "    model = FastText(size=size, window=window, min_count=1,sg=sg,min_n=3,max_n=6,negative=5,word_ngrams=1)#?\n",
    "    print(\"Reading corpus\"+str(small)+\"...\")\n",
    "    if(small==1):\n",
    "        print(\"Reading the small corpus\")\n",
    "        model.build_vocab(sentences=MyIterSmall())\n",
    "    else:  \n",
    "        print(\"Reading the huge corpus\")\n",
    "        model.build_vocab(sentences=MyIterHuge())\n",
    "        \n",
    "    total_examples = model.corpus_count\n",
    "    \n",
    "    #train\n",
    "    print(\"Model training: \"+modelName)\n",
    "    start = time.time()\n",
    "    if(small==1):\n",
    "        model.train(sentences=MyIterSmall(), total_examples=total_examples, epochs=5)\n",
    "    else: model.train(sentences=MyIterHuge(), total_examples=total_examples, epochs=5)\n",
    "        \n",
    "    \n",
    "    print(\"Model trained: \"+modelName)\n",
    "    print(\"Fasttext training time: \"+str(time.time()-start))\n",
    "    \n",
    "    return modelName,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    #print(directory)\n",
    "    if not os.path.exists(directory):\n",
    "        print(file_path+\" not existed, creating...\")\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(modelName,model):\n",
    "    fnameS=os.getcwd()+\"\\\\WEs\\\\gensim_fasttext\\\\\"+modelName+\"\\\\\"+modelName+\".model\"\n",
    "    ensure_dir(fnameS)\n",
    "    fname = get_tmpfile(fnameS)\n",
    "    print(\"Saving model to \"+fnameS)\n",
    "    \n",
    "    model.save(fname)\n",
    "    model.wv.save_word2vec_format(fnameS[:-5]+'vec',binary=False)\n",
    "    print(\"Model saved: \"+modelName)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(small,window,size,sg):\n",
    "    \n",
    "    modelName='ft_s'+str(small)+'_w'+str(window)+'_d' +str(size)+'_sg' +str(sg)\n",
    "    fnameS=os.getcwd()+\"\\\\WEs\\\\gensim_fasttext\\\\\"+modelName+\"\\\\\"+modelName+\".model\"\n",
    "    fname = get_tmpfile(fnameS)\n",
    "    print(\"Loading model from \"+fnameS)\n",
    "    model = FastText.load(fname)\n",
    "    print(\"Model loaded: \"+modelName)\n",
    "    return modelName,model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analogies evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_handler(modelName,topn):\n",
    "\n",
    "    logName = \"evalLogs\\ \"+ modelName +\"_evalT\"+str(topn)+\".log\"\n",
    "    fhandler = logging.FileHandler(logName, 'w',encoding=\"UTF-8\")\n",
    "    \n",
    "    # create formatter and add it to the handler\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fhandler.setFormatter(formatter)\n",
    "    return fhandler\n",
    "    \n",
    "def setup_logger(name, modelName,topn, level=logging.DEBUG):\n",
    "\n",
    "    handler = setup_handler(modelName,topn) \n",
    "    \n",
    "    logger = logging.getLogger(name +\"_evalT\"+str(topn))\n",
    "    logger.setLevel(level)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    return logger   \n",
    "\n",
    "\n",
    "def evaluate_word_analogies2(self, modelName,topn,analogies, restrict_vocab=300000, case_insensitive=False, dummy4unknown=False):\n",
    "        \"\"\"Compute performance of the model on an analogy test set.\n",
    "\n",
    "        This is modern variant of :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.accuracy`, see\n",
    "        `discussion on GitHub #1935 <https://github.com/RaRe-Technologies/gensim/pull/1935>`_.\n",
    "\n",
    "        The accuracy is reported (printed to log and returned as a score) for each section separately,\n",
    "        plus there's one aggregate summary at the end.\n",
    "\n",
    "        This method corresponds to the `compute-accuracy` script of the original C word2vec.\n",
    "        See also `Analogy (State of the art) <https://aclweb.org/aclwiki/Analogy_(State_of_the_art)>`_.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        analogies : str\n",
    "            Path to file, where lines are 4-tuples of words, split into sections by \": SECTION NAME\" lines.\n",
    "            See `gensim/test/test_data/questions-words.txt` as example.\n",
    "        restrict_vocab : int, optional\n",
    "            Ignore all 4-tuples containing a word not in the first `restrict_vocab` words.\n",
    "            This may be meaningful if you've sorted the model vocabulary by descending frequency (which is standard\n",
    "            in modern word embedding models).\n",
    "        case_insensitive : bool, optional\n",
    "            If True - convert all words to their uppercase form before evaluating the performance.\n",
    "            Useful to handle case-mismatch between training tokens and words in the test set.\n",
    "            In case of multiple case variants of a single word, the vector for the first occurrence\n",
    "            (also the most frequent if vocabulary is sorted) is taken.\n",
    "        dummy4unknown : bool, optional\n",
    "            If True - produce zero accuracies for 4-tuples with out-of-vocabulary words.\n",
    "            Otherwise, these tuples are skipped entirely and not used in the evaluation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "            The overall evaluation score on the entire evaluation set\n",
    "        sections : list of dict of {str : str or list of tuple of (str, str, str, str)}\n",
    "            Results broken down by each section of the evaluation set. Each dict contains the name of the section\n",
    "            under the key 'section', and lists of correctly and incorrectly predicted 4-tuples of words under the\n",
    "            keys 'correct' and 'incorrect'.\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"evaluating T\"+str(topn))\n",
    "        print(\"d4u:\"+str(dummy4unknown))\n",
    "        if(dummy4unknown): modelName=modelName+\"_d4u\"\n",
    "        #get default analogies score\n",
    "        evalScoreT1=self.evaluate_word_analogies(analogies,dummy4unknown=dummy4unknown)[0]\n",
    "        #get logger\n",
    "\n",
    "        logger=setup_logger(modelName,modelName,topn)\n",
    "        \n",
    "\n",
    "        \n",
    "        ok_vocab = [(w, self.vocab[w]) for w in self.index2word[:restrict_vocab]]\n",
    "        ok_vocab = {w.upper(): v for w, v in reversed(ok_vocab)} if case_insensitive else dict(ok_vocab)\n",
    "        oov = 0\n",
    "        logger.info(\"Evaluating word analogies for top %i words in the model on %s\", restrict_vocab, analogies)\n",
    "        sections, section = [], None\n",
    "        quadruplets_no = 0\n",
    "\n",
    "        for line_no, line in enumerate(utils.smart_open(analogies)):\n",
    "            line = utils.to_unicode(line)\n",
    "            if line.startswith(': '):\n",
    "                # a new section starts => store the old section\n",
    "                if section:\n",
    "                    sections.append(section)\n",
    "                    self._log_evaluate_word_analogies(section)\n",
    "                section = {'section': line.lstrip(': ').strip(), 'correct': [], 'incorrect': []}\n",
    "            else:\n",
    "                if not section:\n",
    "                    raise ValueError(\"Missing section header before line #%i in %s\" % (line_no, analogies))\n",
    "                try:\n",
    "                    if case_insensitive:\n",
    "                        a, b, c, expected = [word.upper() for word in line.split()]\n",
    "                    else:\n",
    "                        a, b, c, expected = [word for word in line.split()]\n",
    "                except ValueError:\n",
    "                    logger.info(\"Skipping invalid line #%i in %s\", line_no, analogies)\n",
    "                    continue\n",
    "                quadruplets_no += 1\n",
    "                if a not in ok_vocab or b not in ok_vocab or c not in ok_vocab or expected not in ok_vocab:\n",
    "                    oov += 1\n",
    "                    if dummy4unknown:\n",
    "                        logger.debug('Zero accuracy for line #%d with OOV words: %s', line_no, line.strip())\n",
    "                        section['incorrect'].append((a, b, c, expected))\n",
    "                    else:\n",
    "                        logger.debug(\"Skipping line #%i with OOV words: %s\", line_no, line.strip())\n",
    "                    continue\n",
    "                original_vocab = self.vocab\n",
    "                self.vocab = ok_vocab\n",
    "                ignore = {a, b, c}  # input words to be ignored\n",
    "                predicted = None\n",
    "                logger.info('Start predicting: %s + %s - %s = %s',b, c,a, expected)\n",
    "                # find the most likely prediction using 3CosAdd (vector offset) method\n",
    "                # TODO: implement 3CosMul and set-based methods for solving analogies\n",
    "                #print(\"topn=\"+str(topn))\n",
    "                sims = self.most_similar(positive=[b, c], negative=[a], topn=topn, restrict_vocab=restrict_vocab)\n",
    "                #print(a,b,c,sims)\n",
    "                self.vocab = original_vocab\n",
    "                predicted10=0\n",
    "                topN=1\n",
    "                for element in sims:\n",
    "                    predicted = element[0].upper() if case_insensitive else element[0]\n",
    "                    sim=element[1]\n",
    "                    #print(\"predicted \"+predicted)\n",
    "                    #print(\"expected \"+expected)\n",
    "                    if predicted in ok_vocab and predicted not in ignore:\n",
    "                        if predicted != expected:\n",
    "                            logger.debug(\"%s: expected %s, predicted %s,sim %s,top %i\", line.strip(), expected, predicted,sim,topN)\n",
    "                            topN+=1\n",
    "                        #break\n",
    "                    if predicted == expected:\n",
    "                        logger.info('Expected word found: %s + %s - %s = %s, sim %s, top %i',b, c,a, expected,sim,topN)\n",
    "                        #print(\"!!!\")\n",
    "                        section['correct'].append((a, b, c, expected,predicted,sim,topN))\n",
    "                        predicted10=1\n",
    "                        break\n",
    "                if predicted10==0:\n",
    "                    section['incorrect'].append((a, b, c, expected,predicted))\n",
    "        if section:\n",
    "            # store the last section, too\n",
    "            sections.append(section)\n",
    "            self._log_evaluate_word_analogies(section)\n",
    "\n",
    "        total = {\n",
    "            'section': 'Total accuracy',\n",
    "            'correct': list(chain.from_iterable(s['correct'] for s in sections)),\n",
    "            'incorrect': list(chain.from_iterable(s['incorrect'] for s in sections)),\n",
    "        }\n",
    "        oov_ratio = float(oov) / quadruplets_no * 100\n",
    "        logger.info('Quadruplets with out-of-vocabulary words: %.1f%%', oov_ratio)\n",
    "        print('Quadruplets with out-of-vocabulary words: ', oov_ratio)\n",
    "        if not dummy4unknown:\n",
    "            logger.info(\n",
    "                'NB: analogies containing OOV words were skipped from evaluation! '\n",
    "                'To change this behavior, use \"dummy4unknown=True\"'\n",
    "            )\n",
    "        analogies_score = self._log_evaluate_word_analogies(total)\n",
    "        sections.append(total)\n",
    "        mean_sim,mean_top=correctWord_sim(total)\n",
    "        logger.info('evalScoreT1: %.4f',evalScoreT1)\n",
    "        logger.info('evalScoreT%i: %.4f',topn, analogies_score)\n",
    "        logger.info( 'mean_sim: %.4f', mean_sim)\n",
    "        logger.info('mean_top: %.4f',mean_top)\n",
    "        print('evalScoreT1:',evalScoreT1)\n",
    "        print('evalScoreT'+str(topn)+\": \"+str(analogies_score))\n",
    "        print( 'mean_sim: ', mean_sim)\n",
    "        print('mean_top: ',mean_top)\n",
    "        # Return the overall score and the full lists of correct and incorrect analogies\n",
    "        logging.shutdown()\n",
    "        print(\"evaluating done.\")\n",
    "        \n",
    "        return evalScoreT1,mean_sim,mean_top, analogies_score, sections\n",
    "    \n",
    "def correctWord_sim(total):\n",
    "    corrects=total['correct']\n",
    "    sim=[]\n",
    "    top=[]\n",
    "    for c in corrects:\n",
    "        sim.append(c[5])\n",
    "        top.append(c[6])\n",
    "    #print(sim)\n",
    "    if len(sim)!=0: mean_sim=sum(sim)/len(sim)\n",
    "    else: mean_sim=0\n",
    "    if len(top)!=0: mean_top=sum(top)/len(top)\n",
    "    else: mean_top=0\n",
    "    return mean_sim,mean_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# workflow1: train fasttext models and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_train_eval(small,window,size,sg,analogies):\n",
    "    #train\n",
    "    modelName,model=train_fasttext(small,window,size,sg)\n",
    "    #save trained model\n",
    "    save_model(modelName,model)\n",
    "    #eval\n",
    "    evaluate_word_analogies2(model.wv, modelName,3,analogies)\n",
    "    evaluate_word_analogies2(model.wv, modelName,5,analogies)\n",
    "    evaluate_word_analogies2(model.wv, modelName,10,analogies)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# workflow2: load trained fasttext models and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_load_eval(small,window,size,sg,analogies,d4u=False):    \n",
    "    #load trained model\n",
    "    modelName,model=load_model(small,window,size,sg)\n",
    "    #eval\n",
    "    if not (d4u):\n",
    "        evaluate_word_analogies2(model.wv, modelName,3,analogies)\n",
    "        evaluate_word_analogies2(model.wv, modelName,5,analogies)\n",
    "        evaluate_word_analogies2(model.wv, modelName,10,analogies)\n",
    "    else:\n",
    "        evaluate_word_analogies2(model.wv, modelName+\"_d4u\",3,analogies,dummy4unknown=True)\n",
    "        evaluate_word_analogies2(model.wv, modelName+\"_d4u\",5,analogies,dummy4unknown=True)\n",
    "        evaluate_word_analogies2(model.wv, modelName+\"_d4u\",10,analogies,dummy4unknown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training and evaluating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ft_s1_w3_d100_sg0 \n",
    "(small=1,window=3,size=100,sg=0,\n",
    "min_count=1,epochs=5,min_n=3,max_n=6,negative=5,word_ngrams=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading corpus1...\n",
      "Reading the small corpus\n",
      "Model training: ft_s1_w3_d100_sg0\n",
      "Model trained: ft_s1_w3_d100_sg0\n",
      "Fasttext training time: 614.4952123165131\n",
      "Saving model to C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s1_w3_d100_sg0\\ft_s1_w3_d100_sg0.model\n",
      "Model saved: ft_s1_w3_d100_sg0\n"
     ]
    }
   ],
   "source": [
    "ft_train_eval(1,3,100,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s1_w3_d100_sg0\\ft_s1_w3_d100_sg0.model\n",
      "Model loaded: ft_s1_w3_d100_sg0\n"
     ]
    }
   ],
   "source": [
    "ft_load_eval(1,3,100,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading corpus1...\n",
      "Reading the small corpus\n",
      "Model training: ft_s1_w3_d100_sg1\n",
      "Model trained: ft_s1_w3_d100_sg1\n",
      "Fasttext training time: 867.0004193782806\n",
      "Saving model to C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s1_w3_d100_sg1\\ft_s1_w3_d100_sg1.model\n",
      "Model saved: ft_s1_w3_d100_sg1\n"
     ]
    }
   ],
   "source": [
    "ft_train_eval(1,3,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s1_w3_d100_sg1\\ft_s1_w3_d100_sg1.model\n",
      "Model loaded: ft_s1_w3_d100_sg1\n",
      "evaluating T3\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_load_eval(1,3,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading corpus1...\n",
      "Reading the small corpus\n",
      "Model training: ft_s1_w3_d300_sg0\n",
      "Model trained: ft_s1_w3_d300_sg0\n",
      "Fasttext training time: 1921.7276992797852\n",
      "C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s1_w3_d300_sg0\\ft_s1_w3_d300_sg0.model not existed, creating...\n",
      "Saving model to C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s1_w3_d300_sg0\\ft_s1_w3_d300_sg0.model\n",
      "Model saved: ft_s1_w3_d300_sg0\n"
     ]
    }
   ],
   "source": [
    "ft_train_eval(1,3,300,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s1_w3_d300_sg0\\ft_s1_w3_d300_sg0.model\n",
      "Model loaded: ft_s1_w3_d300_sg0\n",
      "evaluating T3\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_load_eval(1,3,300,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s1_w3_d300_sg1\\ft_s1_w3_d300_sg1.model\n",
      "Model loaded: ft_s1_w3_d300_sg1\n",
      "evaluating T3\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_load_eval(1,3,300,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ft_train_eval(1,5,100,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s1_w5_d100_sg0\\ft_s1_w5_d100_sg0.model\n",
      "Model loaded: ft_s1_w5_d100_sg0\n",
      "evaluating T3\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_load_eval(1,5,100,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ft_train_eval(1,5,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s1_w5_d100_sg1\\ft_s1_w5_d100_sg1.model\n",
      "Model loaded: ft_s1_w5_d100_sg1\n",
      "evaluating T3\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_load_eval(1,5,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ft_train_eval(1,5,300,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s1_w5_d300_sg0\\ft_s1_w5_d300_sg0.model\n",
      "Model loaded: ft_s1_w5_d300_sg0\n",
      "evaluating T3\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_load_eval(1,5,300,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading corpus1...\n",
      "Reading the small corpus\n",
      "Model training: ft_s1_w5_d300_sg1\n",
      "Model trained: ft_s1_w5_d300_sg1\n",
      "Fasttext training time: 1900.5142829418182\n",
      "C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s1_w5_d300_sg1\\ft_s1_w5_d300_sg1.model not existed, creating...\n",
      "Saving model to C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s1_w5_d300_sg1\\ft_s1_w5_d300_sg1.model\n",
      "Model saved: ft_s1_w5_d300_sg1\n"
     ]
    }
   ],
   "source": [
    "ft_train_eval(1,5,300,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s1_w5_d300_sg1\\ft_s1_w5_d300_sg1.model\n",
      "Model loaded: ft_s1_w5_d300_sg1\n",
      "evaluating T3\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_load_eval(1,5,300,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ft_train_eval(0,3,100,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w3_d100_sg0\\ft_s0_w3_d100_sg0.model\n",
      "Model loaded: ft_s0_w3_d100_sg0\n",
      "evaluating T3\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_load_eval(0,3,100,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ft_train_eval(0,3,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w3_d100_sg1\\ft_s0_w3_d100_sg1.model\n",
      "Model loaded: ft_s0_w3_d100_sg1\n",
      "evaluating T3\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_load_eval(0,3,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ft_train_eval(0,3,300,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w3_d300_sg0\\ft_s0_w3_d300_sg0.model\n",
      "Model loaded: ft_s0_w3_d300_sg0\n",
      "evaluating T3\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_load_eval(0,3,300,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ft_train_eval(0,3,300,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w3_d300_sg1\\ft_s0_w3_d300_sg1.model\n",
      "Model loaded: ft_s0_w3_d300_sg1\n",
      "evaluating T3\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_load_eval(0,3,300,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading corpus0...\n",
      "Reading the huge corpus\n",
      "Model training: ft_s0_w5_d100_sg0\n",
      "Model trained: ft_s0_w5_d100_sg0\n",
      "Fasttext training time: 6163.8315098285675\n",
      "C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w5_d100_sg0\\ft_s0_w5_d100_sg0.model not existed, creating...\n",
      "Saving model to C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w5_d100_sg0\\ft_s0_w5_d100_sg0.model\n",
      "Model saved: ft_s0_w5_d100_sg0\n"
     ]
    }
   ],
   "source": [
    "ft_train_eval(0,5,100,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w5_d100_sg0\\ft_s0_w5_d100_sg0.model\n",
      "Model loaded: ft_s0_w5_d100_sg0\n",
      "evaluating T3\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_load_eval(0,5,100,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading corpus0...\n",
      "Reading the huge corpus\n",
      "Model training: ft_s0_w5_d100_sg1\n",
      "Model trained: ft_s0_w5_d100_sg1\n",
      "Fasttext training time: 7360.7729778289795\n",
      "C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w5_d100_sg1\\ft_s0_w5_d100_sg1.model not existed, creating...\n",
      "Saving model to C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w5_d100_sg1\\ft_s0_w5_d100_sg1.model\n",
      "Model saved: ft_s0_w5_d100_sg1\n"
     ]
    }
   ],
   "source": [
    "ft_train_eval(0,5,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w5_d100_sg1\\ft_s0_w5_d100_sg1.model\n",
      "Model loaded: ft_s0_w5_d100_sg1\n",
      "evaluating T3\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "#ft_load_eval(0,5,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w5_d100_sg1\\ft_s0_w5_d100_sg1.model\n",
      "Model loaded: ft_s0_w5_d100_sg1\n",
      "evaluating T3\n",
      "d4u:True\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_load_eval(0,5,100,1,analogies,d4u=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading corpus0...\n",
      "Reading the huge corpus\n",
      "Model training: ft_s0_w5_d300_sg0\n",
      "Model trained: ft_s0_w5_d300_sg0\n",
      "Fasttext training time: 15975.812193632126\n",
      "C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w5_d300_sg0\\ft_s0_w5_d300_sg0.model not existed, creating...\n",
      "Saving model to C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w5_d300_sg0\\ft_s0_w5_d300_sg0.model\n",
      "Model saved: ft_s0_w5_d300_sg0\n"
     ]
    }
   ],
   "source": [
    "ft_train_eval(0,5,300,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w5_d300_sg0\\ft_s0_w5_d300_sg0.model\n",
      "Model loaded: ft_s0_w5_d300_sg0\n",
      "evaluating T3\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_load_eval(0,5,300,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading corpus0...\n",
      "Reading the huge corpus\n",
      "Model training: ft_s0_w10_d100_sg1\n",
      "Model trained: ft_s0_w10_d100_sg1\n",
      "Fasttext training time: 4194.701753616333\n",
      "D:\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w10_d100_sg1\\ft_s0_w10_d100_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w10_d100_sg1\\ft_s0_w10_d100_sg1.model\n",
      "Model saved: ft_s0_w10_d100_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.4523809523809524\n",
      "evalScoreT3: 0.6190476190476191\n",
      "mean_sim:  0.861471597964947\n",
      "mean_top:  1.4230769230769231\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.4523809523809524\n",
      "evalScoreT5: 0.6666666666666666\n",
      "mean_sim:  0.8551896320922034\n",
      "mean_top:  1.6785714285714286\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.4523809523809524\n",
      "evalScoreT10: 0.7619047619047619\n",
      "mean_sim:  0.8445845171809196\n",
      "mean_top:  2.5\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_train_eval(0,10,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading corpus0...\n",
      "Reading the huge corpus\n",
      "Model training: ft_s0_w15_d100_sg1\n",
      "Model trained: ft_s0_w15_d100_sg1\n",
      "Fasttext training time: 6451.076989173889\n",
      "D:\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w15_d100_sg1\\ft_s0_w15_d100_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w15_d100_sg1\\ft_s0_w15_d100_sg1.model\n",
      "Model saved: ft_s0_w15_d100_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.2857142857142857\n",
      "evalScoreT3: 0.5952380952380952\n",
      "mean_sim:  0.8640835785865784\n",
      "mean_top:  1.84\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.2857142857142857\n",
      "evalScoreT5: 0.6666666666666666\n",
      "mean_sim:  0.8605573028326035\n",
      "mean_top:  2.142857142857143\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.2857142857142857\n",
      "evalScoreT10: 0.7619047619047619\n",
      "mean_sim:  0.8534691538661718\n",
      "mean_top:  2.875\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_train_eval(0,15,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading corpus0...\n",
      "Reading the huge corpus\n",
      "Model training: ft_s0_w20_d100_sg1\n",
      "Model trained: ft_s0_w20_d100_sg1\n",
      "Fasttext training time: 5944.9982697963715\n",
      "D:\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w20_d100_sg1\\ft_s0_w20_d100_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w20_d100_sg1\\ft_s0_w20_d100_sg1.model\n",
      "Model saved: ft_s0_w20_d100_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.23809523809523808\n",
      "evalScoreT3: 0.5714285714285714\n",
      "mean_sim:  0.8656863744060198\n",
      "mean_top:  2.0\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.23809523809523808\n",
      "evalScoreT5: 0.6190476190476191\n",
      "mean_sim:  0.8631909581331106\n",
      "mean_top:  2.1923076923076925\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.23809523809523808\n",
      "evalScoreT10: 0.6904761904761905\n",
      "mean_sim:  0.851657719447695\n",
      "mean_top:  2.9310344827586206\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_train_eval(0,20,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading corpus0...\n",
      "Reading the huge corpus\n",
      "Model training: ft_s0_w25_d100_sg1\n",
      "Model trained: ft_s0_w25_d100_sg1\n",
      "Fasttext training time: 4911.504615783691\n",
      "D:\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w25_d100_sg1\\ft_s0_w25_d100_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w25_d100_sg1\\ft_s0_w25_d100_sg1.model\n",
      "Model saved: ft_s0_w25_d100_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.14285714285714285\n",
      "evalScoreT3: 0.4523809523809524\n",
      "mean_sim:  0.8722635068391499\n",
      "mean_top:  1.9473684210526316\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.14285714285714285\n",
      "evalScoreT5: 0.5476190476190477\n",
      "mean_sim:  0.8668414457984592\n",
      "mean_top:  2.391304347826087\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.14285714285714285\n",
      "evalScoreT10: 0.6666666666666666\n",
      "mean_sim:  0.860552225794111\n",
      "mean_top:  3.3214285714285716\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_train_eval(0,25,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading corpus0...\n",
      "Reading the huge corpus\n",
      "Model training: ft_s0_w30_d100_sg1\n",
      "Model trained: ft_s0_w30_d100_sg1\n",
      "Fasttext training time: 5338.544718980789\n",
      "D:\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w30_d100_sg1\\ft_s0_w30_d100_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w30_d100_sg1\\ft_s0_w30_d100_sg1.model\n",
      "Model saved: ft_s0_w30_d100_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.09523809523809523\n",
      "evalScoreT3: 0.42857142857142855\n",
      "mean_sim:  0.8678166667620341\n",
      "mean_top:  2.2777777777777777\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.09523809523809523\n",
      "evalScoreT5: 0.5238095238095238\n",
      "mean_sim:  0.8620118959383531\n",
      "mean_top:  2.6363636363636362\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.09523809523809523\n",
      "evalScoreT10: 0.6190476190476191\n",
      "mean_sim:  0.8562173361961658\n",
      "mean_top:  3.3846153846153846\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_train_eval(0,30,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading corpus0...\n",
      "Reading the huge corpus\n",
      "Model training: ft_s0_w5_d400_sg1\n",
      "Model trained: ft_s0_w5_d400_sg1\n",
      "Fasttext training time: 6355.152570486069\n",
      "D:\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w5_d400_sg1\\ft_s0_w5_d400_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w5_d400_sg1\\ft_s0_w5_d400_sg1.model\n",
      "Model saved: ft_s0_w5_d400_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.35714285714285715\n",
      "evalScoreT3: 0.4523809523809524\n",
      "mean_sim:  0.7688824503045333\n",
      "mean_top:  1.3157894736842106\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.35714285714285715\n",
      "evalScoreT5: 0.5238095238095238\n",
      "mean_sim:  0.7559415968981656\n",
      "mean_top:  1.7727272727272727\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.35714285714285715\n",
      "evalScoreT10: 0.5476190476190477\n",
      "mean_sim:  0.7522268606268842\n",
      "mean_top:  1.9565217391304348\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_train_eval(0,5,400,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading corpus0...\n",
      "Reading the huge corpus\n",
      "Model training: ft_s0_w5_d500_sg1\n",
      "Model trained: ft_s0_w5_d500_sg1\n",
      "Fasttext training time: 5914.944427728653\n",
      "D:\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w5_d500_sg1\\ft_s0_w5_d500_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w5_d500_sg1\\ft_s0_w5_d500_sg1.model\n",
      "Model saved: ft_s0_w5_d500_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.2619047619047619\n",
      "evalScoreT3: 0.4523809523809524\n",
      "mean_sim:  0.7557979884900545\n",
      "mean_top:  1.5263157894736843\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.2619047619047619\n",
      "evalScoreT5: 0.5\n",
      "mean_sim:  0.7508777550288609\n",
      "mean_top:  1.7619047619047619\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.2619047619047619\n",
      "evalScoreT10: 0.5476190476190477\n",
      "mean_sim:  0.7418074659679247\n",
      "mean_top:  2.4347826086956523\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_train_eval(0,5,500,1,analogies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check vocabulary size and thevector diemsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from D:\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w5_d100_sg1\\ft_s0_w5_d100_sg1.model\n",
      "Model loaded: ft_s0_w5_d100_sg1\n"
     ]
    }
   ],
   "source": [
    "modelName,model=load_model(0,5,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ft_s0_w5_d100_sg1\n",
      "Vocabulary size 695675\n",
      "Word vector length: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Model: \"+modelName)\n",
    "print(\"Vocabulary size\", len(list(model.wv.vocab.keys())))\n",
    "print(\"Word vector length:\", len(model.wv[\"Mann\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_basemodel_info(modelPath, model):\n",
    "    print(\"###modelPath: \", modelPath)\n",
    "    print(\"window: \",model.window)\n",
    "    print(\"embed size: \",len(model.wv[\"mann\"]))\n",
    "    print(\"sg: \"  , model.sg)\n",
    "    print(\"epochs: \", model.epochs)\n",
    "    print(\"min_count: \",model.vocabulary.min_count)\n",
    "    print(\"negative sampling: \", model.negative)\n",
    "    print(\"min_n:\",model.min_n)\n",
    "    print(\"max_n:\",model.max_n)\n",
    "    print(\"Vocabulary sie: \",len(model.wv.vectors_vocab))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###modelPath:  ft_s0_w5_d100_sg1\n",
      "window:  5\n",
      "embed size:  100\n",
      "sg:  1\n",
      "epochs:  5\n",
      "min_count:  1\n",
      "negative sampling:  5\n",
      "min_n: 3\n",
      "max_n: 6\n",
      "Vocabulary sie:  695675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `min_n` (Attribute will be removed in 4.0.0, use wv.min_n instead).\n",
      "  if __name__ == '__main__':\n",
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `max_n` (Attribute will be removed in 4.0.0, use wv.max_n instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "print_basemodel_info(modelName,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from D:\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s1_w5_d100_sg1\\ft_s1_w5_d100_sg1.model\n",
      "Model loaded: ft_s1_w5_d100_sg1\n"
     ]
    }
   ],
   "source": [
    "modelName,model=load_model(1,5,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###modelPath:  ft_s1_w5_d100_sg1\n",
      "window:  5\n",
      "embed size:  100\n",
      "sg:  1\n",
      "epochs:  5\n",
      "min_count:  1\n",
      "negative sampling:  5\n",
      "min_n: 3\n",
      "max_n: 6\n",
      "Vocabulary sie:  282731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `min_n` (Attribute will be removed in 4.0.0, use wv.min_n instead).\n",
      "  if __name__ == '__main__':\n",
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `max_n` (Attribute will be removed in 4.0.0, use wv.max_n instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "print_basemodel_info(modelName,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sexverkufer', 0.8573232889175415),\n",
       " ('Kufer', 0.8427373170852661),\n",
       " ('Systemverkufer', 0.8417536020278931),\n",
       " ('Autoverkufer', 0.8347867727279663),\n",
       " ('Endkufer', 0.8296511769294739),\n",
       " ('Endverkufer', 0.8273990154266357),\n",
       " ('Hofverkufern', 0.826798141002655),\n",
       " ('Einkufer', 0.8267784118652344),\n",
       " ('Verkufern', 0.8264048099517822),\n",
       " ('Weiterverkufer', 0.8252648115158081)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query: Vermieter Mieter Verkufer Kufer\n",
    "model.wv.most_similar(positive=[\"Mieter\", \"Verkufer\"], negative=[\"Vermieter\"], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query: Vermieter Mieter Verkufer Kufer\n",
    "model.most_similar(positive=[\"Kufer\", \"Verkufer\"], negative=[\"Vermieter\"], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"Mieter\", \"Verkufer\"], negative=[\"Vermieter\"], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"Mieter\", \"Verkufer\"], negative=[\"Vermieter\"], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"Mieter\", \"Verkufer\"], negative=[\"Vermieter\"], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ft_s1_w5_d100_sg1\n",
      "Vocabulary size 282731\n",
      "Word vector length: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Model: \"+modelName)\n",
    "print(\"Vocabulary size\", len(list(model.wv.vocab.keys())))\n",
    "print(\"Word vector length:\", len(model.wv[\"Mann\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.fasttext.FastText"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.keyedvectors.FastTextKeyedVectors"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_vsd(modelName,model):\n",
    "    print(\"Vocabulary size\", len(list(model.wv.vocab.keys())))\n",
    "    print(\"Word vector length:\", len(model.wv[\"Mann\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## continue training prtrained models on legal corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pt_ft_d300_ky = FastText.load_fasttext_format(modelPath4,full_model=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
