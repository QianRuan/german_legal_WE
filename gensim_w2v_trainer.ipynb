{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "#from gensim.models.fasttext import FastText \n",
    "from gensim.test.utils import datapath\n",
    "import time\n",
    "from gensim.test.utils import get_tmpfile\n",
    "import logging\n",
    "from gensim import utils\n",
    "from itertools import chain\n",
    "from gensim.utils import tokenize\n",
    "import smart_open\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\german_legal_WE'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogies = datapath(os.getcwd()+'\\\\german-legal-analogies.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = Word2Vec(MyIterSmall(),size=100, window=3, min_count=1,sg=0,negative=5,workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save(\"word2vecTest.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#evaluate_word_analogies2(model.wv, \"w2vTest\",10,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## open the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the small legal corpus\n",
    "class MyIterSmall(object):\n",
    "    def __iter__(self):\n",
    "        path = datapath(os.getcwd()+'\\\\German_legal_corpora\\\\cleaned-small-legal-corpus.txt')\n",
    "        with smart_open.smart_open(path, 'r', encoding='utf-8') as fin:\n",
    "            for line in fin:\n",
    "                yield list(tokenize(line))\n",
    "#open the huge legal corpus\n",
    "class MyIterHuge(object):\n",
    "    def __iter__(self):\n",
    "        path = datapath(os.getcwd()+'\\\\German_legal_corpora\\\\cleaned-huge-legal-corpus.txt')\n",
    "        with smart_open.smart_open(path, 'r', encoding='utf-8') as fin:\n",
    "            for line in fin:\n",
    "                yield list(tokenize(line))\n",
    "class MyIterTest(object):\n",
    "    def __iter__(self):\n",
    "        path = datapath(os.getcwd()+'\\\\German_legal_corpora\\\\test-huge.txt')\n",
    "        with smart_open.smart_open(path, 'r', encoding='utf-8') as fin:\n",
    "            for line in fin:\n",
    "                yield list(tokenize(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## train_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_w2v(small,window,size,sg):\n",
    "    \n",
    "\n",
    "    modelName='w2v_s'+str(small)+'_w'+str(window)+'_d' +str(size)+'_sg' +str(sg)\n",
    "    \n",
    "    \n",
    "    #train\n",
    "    print(\"Model training: \"+modelName)\n",
    "    start = time.time()\n",
    "    if(small==1):\n",
    "        model = Word2Vec(MyIterSmall(),size=size, window=window, min_count=1,sg=sg,negative=5,workers=4)\n",
    "    else: model = Word2Vec(MyIterHuge(),size=size, window=window, min_count=1,sg=sg,negative=5,workers=4)\n",
    "        \n",
    "    \n",
    "    print(\"Model trained: \"+modelName)\n",
    "    print(\"Fasttext training time: \"+str(time.time()-start))\n",
    "    \n",
    "    return modelName,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    #print(directory)\n",
    "    if not os.path.exists(directory):\n",
    "        print(file_path+\" not existed, creating...\")\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_w2v(modelName,model):\n",
    "    \n",
    "    fnameS=os.getcwd()+\"\\\\WEs\\\\gensim_w2v\\\\\"+modelName+\"\\\\\"+modelName+\".model\"\n",
    "    ensure_dir(fnameS)\n",
    "    fname = get_tmpfile(fnameS)\n",
    "    print(\"Saving model to \"+fnameS)\n",
    "    #save the full model\n",
    "    model.save(fname)\n",
    "    #save the model in word2vec format\n",
    "    model.wv.save_word2vec_format(fnameS[:-5]+'vec',binary=False)\n",
    "    print(\"Model saved: \"+modelName)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_w2v(small,window,size,sg):\n",
    "    \n",
    "    modelName='w2v_s'+str(small)+'_w'+str(window)+'_d' +str(size)+'_sg' +str(sg)\n",
    "    fnameS=os.getcwd()+\"\\\\WEs\\\\gensim_w2v\\\\\"+modelName+\"\\\\\"+modelName+\".model\"\n",
    "    fname = get_tmpfile(fnameS)\n",
    "    print(\"Loading model from \"+fnameS)\n",
    "    model = Word2Vec.load(fname)\n",
    "    print(\"Model loaded: \"+modelName)\n",
    "    return modelName,model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analogies evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_handler(modelName,topn):\n",
    "\n",
    "    logName = \"evalLogs\\ \"+ modelName +\"_evalT\"+str(topn)+\".log\"\n",
    "    fhandler = logging.FileHandler(logName, 'w',encoding=\"UTF-8\")\n",
    "    \n",
    "    # create formatter and add it to the handler\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fhandler.setFormatter(formatter)\n",
    "    return fhandler\n",
    "    \n",
    "def setup_logger(name, modelName,topn, level=logging.DEBUG):\n",
    "\n",
    "    handler = setup_handler(modelName,topn) \n",
    "    \n",
    "    logger = logging.getLogger(name +\"_evalT\"+str(topn))\n",
    "    logger.setLevel(level)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    return logger   \n",
    "\n",
    "\n",
    "def evaluate_word_analogies2(self, modelName,topn,analogies, restrict_vocab=300000, case_insensitive=False, dummy4unknown=False):\n",
    "        \"\"\"Compute performance of the model on an analogy test set.\n",
    "\n",
    "        This is modern variant of :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.accuracy`, see\n",
    "        `discussion on GitHub #1935 <https://github.com/RaRe-Technologies/gensim/pull/1935>`_.\n",
    "\n",
    "        The accuracy is reported (printed to log and returned as a score) for each section separately,\n",
    "        plus there's one aggregate summary at the end.\n",
    "\n",
    "        This method corresponds to the `compute-accuracy` script of the original C word2vec.\n",
    "        See also `Analogy (State of the art) <https://aclweb.org/aclwiki/Analogy_(State_of_the_art)>`_.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        analogies : str\n",
    "            Path to file, where lines are 4-tuples of words, split into sections by \": SECTION NAME\" lines.\n",
    "            See `gensim/test/test_data/questions-words.txt` as example.\n",
    "        restrict_vocab : int, optional\n",
    "            Ignore all 4-tuples containing a word not in the first `restrict_vocab` words.\n",
    "            This may be meaningful if you've sorted the model vocabulary by descending frequency (which is standard\n",
    "            in modern word embedding models).\n",
    "        case_insensitive : bool, optional\n",
    "            If True - convert all words to their uppercase form before evaluating the performance.\n",
    "            Useful to handle case-mismatch between training tokens and words in the test set.\n",
    "            In case of multiple case variants of a single word, the vector for the first occurrence\n",
    "            (also the most frequent if vocabulary is sorted) is taken.\n",
    "        dummy4unknown : bool, optional\n",
    "            If True - produce zero accuracies for 4-tuples with out-of-vocabulary words.\n",
    "            Otherwise, these tuples are skipped entirely and not used in the evaluation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "            The overall evaluation score on the entire evaluation set\n",
    "        sections : list of dict of {str : str or list of tuple of (str, str, str, str)}\n",
    "            Results broken down by each section of the evaluation set. Each dict contains the name of the section\n",
    "            under the key 'section', and lists of correctly and incorrectly predicted 4-tuples of words under the\n",
    "            keys 'correct' and 'incorrect'.\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"evaluating T\"+str(topn))\n",
    "        print(\"d4u:\"+str(dummy4unknown))\n",
    "        if(dummy4unknown): modelName=modelName+\"_d4u\"\n",
    "        #get default analogies score\n",
    "        evalScoreT1=self.evaluate_word_analogies(analogies,dummy4unknown=dummy4unknown)[0]\n",
    "        #get logger\n",
    "\n",
    "        logger=setup_logger(modelName,modelName,topn)\n",
    "        \n",
    "\n",
    "        \n",
    "        ok_vocab = [(w, self.vocab[w]) for w in self.index2word[:restrict_vocab]]\n",
    "        ok_vocab = {w.upper(): v for w, v in reversed(ok_vocab)} if case_insensitive else dict(ok_vocab)\n",
    "        oov = 0\n",
    "        logger.info(\"Evaluating word analogies for top %i words in the model on %s\", restrict_vocab, analogies)\n",
    "        sections, section = [], None\n",
    "        quadruplets_no = 0\n",
    "\n",
    "        for line_no, line in enumerate(utils.smart_open(analogies)):\n",
    "            line = utils.to_unicode(line)\n",
    "            if line.startswith(': '):\n",
    "                # a new section starts => store the old section\n",
    "                if section:\n",
    "                    sections.append(section)\n",
    "                    self._log_evaluate_word_analogies(section)\n",
    "                section = {'section': line.lstrip(': ').strip(), 'correct': [], 'incorrect': []}\n",
    "            else:\n",
    "                if not section:\n",
    "                    raise ValueError(\"Missing section header before line #%i in %s\" % (line_no, analogies))\n",
    "                try:\n",
    "                    if case_insensitive:\n",
    "                        a, b, c, expected = [word.upper() for word in line.split()]\n",
    "                    else:\n",
    "                        a, b, c, expected = [word for word in line.split()]\n",
    "                except ValueError:\n",
    "                    logger.info(\"Skipping invalid line #%i in %s\", line_no, analogies)\n",
    "                    continue\n",
    "                quadruplets_no += 1\n",
    "                if a not in ok_vocab or b not in ok_vocab or c not in ok_vocab or expected not in ok_vocab:\n",
    "                    oov += 1\n",
    "                    if dummy4unknown:\n",
    "                        logger.debug('Zero accuracy for line #%d with OOV words: %s', line_no, line.strip())\n",
    "                        section['incorrect'].append((a, b, c, expected))\n",
    "                    else:\n",
    "                        logger.debug(\"Skipping line #%i with OOV words: %s\", line_no, line.strip())\n",
    "                    continue\n",
    "                original_vocab = self.vocab\n",
    "                self.vocab = ok_vocab\n",
    "                ignore = {a, b, c}  # input words to be ignored\n",
    "                predicted = None\n",
    "                logger.info('Start predicting: %s + %s - %s = %s',b, c,a, expected)\n",
    "                # find the most likely prediction using 3CosAdd (vector offset) method\n",
    "                # TODO: implement 3CosMul and set-based methods for solving analogies\n",
    "                #print(\"topn=\"+str(topn))\n",
    "                sims = self.most_similar(positive=[b, c], negative=[a], topn=topn, restrict_vocab=restrict_vocab)\n",
    "                #print(a,b,c,sims)\n",
    "                self.vocab = original_vocab\n",
    "                predicted10=0\n",
    "                topN=1\n",
    "                for element in sims:\n",
    "                    predicted = element[0].upper() if case_insensitive else element[0]\n",
    "                    sim=element[1]\n",
    "                    #print(\"predicted \"+predicted)\n",
    "                    #print(\"expected \"+expected)\n",
    "                    if predicted in ok_vocab and predicted not in ignore:\n",
    "                        if predicted != expected:\n",
    "                            logger.debug(\"%s: expected %s, predicted %s,sim %s,top %i\", line.strip(), expected, predicted,sim,topN)\n",
    "                            topN+=1\n",
    "                        #break\n",
    "                    if predicted == expected:\n",
    "                        logger.info('Expected word found: %s + %s - %s = %s, sim %s, top %i',b, c,a, expected,sim,topN)\n",
    "                        #print(\"!!!\")\n",
    "                        section['correct'].append((a, b, c, expected,predicted,sim,topN))\n",
    "                        predicted10=1\n",
    "                        break\n",
    "                if predicted10==0:\n",
    "                    section['incorrect'].append((a, b, c, expected,predicted))\n",
    "        if section:\n",
    "            # store the last section, too\n",
    "            sections.append(section)\n",
    "            self._log_evaluate_word_analogies(section)\n",
    "\n",
    "        total = {\n",
    "            'section': 'Total accuracy',\n",
    "            'correct': list(chain.from_iterable(s['correct'] for s in sections)),\n",
    "            'incorrect': list(chain.from_iterable(s['incorrect'] for s in sections)),\n",
    "        }\n",
    "        oov_ratio = float(oov) / quadruplets_no * 100\n",
    "        logger.info('Quadruplets with out-of-vocabulary words: %.1f%%', oov_ratio)\n",
    "        print('Quadruplets with out-of-vocabulary words: ', oov_ratio)\n",
    "        if not dummy4unknown:\n",
    "            logger.info(\n",
    "                'NB: analogies containing OOV words were skipped from evaluation! '\n",
    "                'To change this behavior, use \"dummy4unknown=True\"'\n",
    "            )\n",
    "        analogies_score = self._log_evaluate_word_analogies(total)\n",
    "        sections.append(total)\n",
    "        mean_sim,mean_top=correctWord_sim(total)\n",
    "        logger.info('evalScoreT1: %.4f',evalScoreT1)\n",
    "        logger.info('evalScoreT%i: %.4f',topn, analogies_score)\n",
    "        logger.info( 'mean_sim: %.4f', mean_sim)\n",
    "        logger.info('mean_top: %.4f',mean_top)\n",
    "        print('evalScoreT1:',evalScoreT1)\n",
    "        print('evalScoreT'+str(topn)+\": \"+str(analogies_score))\n",
    "        print( 'mean_sim: ', mean_sim)\n",
    "        print('mean_top: ',mean_top)\n",
    "        # Return the overall score and the full lists of correct and incorrect analogies\n",
    "        logging.shutdown()\n",
    "        print(\"evaluating done.\")\n",
    "        \n",
    "        return evalScoreT1,mean_sim,mean_top, analogies_score, sections\n",
    "    \n",
    "def correctWord_sim(total):\n",
    "    corrects=total['correct']\n",
    "    sim=[]\n",
    "    top=[]\n",
    "    for c in corrects:\n",
    "        sim.append(c[5])\n",
    "        top.append(c[6])\n",
    "    #print(sim)\n",
    "    if len(sim)!=0: mean_sim=sum(sim)/len(sim)\n",
    "    else: mean_sim=0\n",
    "    if len(top)!=0: mean_top=sum(top)/len(top)\n",
    "    else: mean_top=0\n",
    "    return mean_sim,mean_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# workflow1: train fasttext models and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_train_eval(small,window,size,sg,analogies):\n",
    "    #train\n",
    "    modelName,model=train_w2v(small,window,size,sg)\n",
    "    #save trained model\n",
    "    save_model_w2v(modelName,model)\n",
    "    #eval\n",
    "    evaluate_word_analogies2(model.wv, modelName,3,analogies)\n",
    "    evaluate_word_analogies2(model.wv, modelName,5,analogies)\n",
    "    evaluate_word_analogies2(model.wv, modelName,10,analogies)\n",
    "    #evaluate_word_analogies2(model.wv, modelName+\"_d4u\",3,analogies,dummy4unknown=True)\n",
    "    #evaluate_word_analogies2(model.wv, modelName+\"_d4u\",5,analogies,dummy4unknown=True)\n",
    "    #evaluate_word_analogies2(model.wv, modelName+\"_d4u\",10,analogies,dummy4unknown=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# workflow2: load trained fasttext models and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_load_eval(small,window,size,sg,analogies):    \n",
    "    #load trained model\n",
    "    modelName,model=load_model_w2v(small,window,size,sg)\n",
    "   \n",
    "    #eval\n",
    "    evaluate_word_analogies2(model.wv, modelName,3,analogies)\n",
    "    evaluate_word_analogies2(model.wv, modelName,5,analogies)\n",
    "    evaluate_word_analogies2(model.wv, modelName,10,analogies)\n",
    "    #evaluate_word_analogies2(model.wv, modelName+\"_d4u\",3,analogies,dummy4unknown=True)\n",
    "    #evaluate_word_analogies2(model.wv, modelName+\"_d4u\",5,analogies,dummy4unknown=True)\n",
    "    #evaluate_word_analogies2(model.wv, modelName+\"_d4u\",10,analogies,dummy4unknown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training and evaluating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## w2v_s1_w3_d100_sg0 \n",
    "(small=1,window=3,size=100,sg=0,\n",
    "min_count=1,epochs=5,min_n=3,max_n=6,negative=5,word_ngrams=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s1_w3_d100_sg0\n",
      "Model trained: w2v_s1_w3_d100_sg0\n",
      "Fasttext training time: 246.3556685447693\n",
      "C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s1_w3_d100_sg0\\w2v_s1_w3_d100_sg0.model not existed, creating...\n",
      "Saving model to C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s1_w3_d100_sg0\\w2v_s1_w3_d100_sg0.model\n",
      "Model saved: w2v_s1_w3_d100_sg0\n"
     ]
    }
   ],
   "source": [
    "#w2v_train_eval(1,3,100,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s1_w3_d100_sg1\n",
      "Model trained: w2v_s1_w3_d100_sg1\n",
      "Fasttext training time: 251.92395997047424\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s1_w3_d100_sg1\\w2v_s1_w3_d100_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s1_w3_d100_sg1\\w2v_s1_w3_d100_sg1.model\n",
      "Model saved: w2v_s1_w3_d100_sg1\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(1,3,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s1_w3_d300_sg0\n",
      "Model trained: w2v_s1_w3_d300_sg0\n",
      "Fasttext training time: 211.60915422439575\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s1_w3_d300_sg0\\w2v_s1_w3_d300_sg0.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s1_w3_d300_sg0\\w2v_s1_w3_d300_sg0.model\n",
      "Model saved: w2v_s1_w3_d300_sg0\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(1,3,300,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s1_w3_d300_sg1\n",
      "Model trained: w2v_s1_w3_d300_sg1\n",
      "Fasttext training time: 314.1383066177368\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s1_w3_d300_sg1\\w2v_s1_w3_d300_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s1_w3_d300_sg1\\w2v_s1_w3_d300_sg1.model\n",
      "Model saved: w2v_s1_w3_d300_sg1\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(1,3,300,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s1_w5_d100_sg0\n",
      "Model trained: w2v_s1_w5_d100_sg0\n",
      "Fasttext training time: 192.2641956806183\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s1_w5_d100_sg0\\w2v_s1_w5_d100_sg0.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s1_w5_d100_sg0\\w2v_s1_w5_d100_sg0.model\n",
      "Model saved: w2v_s1_w5_d100_sg0\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(1,5,100,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s1_w5_d100_sg1\n",
      "Model trained: w2v_s1_w5_d100_sg1\n",
      "Fasttext training time: 262.45893907546997\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s1_w5_d100_sg1\\w2v_s1_w5_d100_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s1_w5_d100_sg1\\w2v_s1_w5_d100_sg1.model\n",
      "Model saved: w2v_s1_w5_d100_sg1\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(1,5,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s1_w5_d300_sg0\n",
      "Model trained: w2v_s1_w5_d300_sg0\n",
      "Fasttext training time: 212.1407880783081\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s1_w5_d300_sg0\\w2v_s1_w5_d300_sg0.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s1_w5_d300_sg0\\w2v_s1_w5_d300_sg0.model\n",
      "Model saved: w2v_s1_w5_d300_sg0\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(1,5,300,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s1_w5_d300_sg1\n",
      "Model trained: w2v_s1_w5_d300_sg1\n",
      "Fasttext training time: 415.63201427459717\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s1_w5_d300_sg1\\w2v_s1_w5_d300_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s1_w5_d300_sg1\\w2v_s1_w5_d300_sg1.model\n",
      "Model saved: w2v_s1_w5_d300_sg1\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(1,5,300,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w3_d100_sg0\n",
      "Model trained: w2v_s0_w3_d100_sg0\n",
      "Fasttext training time: 1116.9372055530548\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w3_d100_sg0\\w2v_s0_w3_d100_sg0.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w3_d100_sg0\\w2v_s0_w3_d100_sg0.model\n",
      "Model saved: w2v_s0_w3_d100_sg0\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,3,100,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w3_d100_sg1\n",
      "Model trained: w2v_s0_w3_d100_sg1\n",
      "Fasttext training time: 1408.3439826965332\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w3_d100_sg1\\w2v_s0_w3_d100_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w3_d100_sg1\\w2v_s0_w3_d100_sg1.model\n",
      "Model saved: w2v_s0_w3_d100_sg1\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,3,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w3_d300_sg0\n",
      "Model trained: w2v_s0_w3_d300_sg0\n",
      "Fasttext training time: 1219.364342212677\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w3_d300_sg0\\w2v_s0_w3_d300_sg0.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w3_d300_sg0\\w2v_s0_w3_d300_sg0.model\n",
      "Model saved: w2v_s0_w3_d300_sg0\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,3,300,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w3_d300_sg1\n",
      "Model trained: w2v_s0_w3_d300_sg1\n",
      "Fasttext training time: 1994.914630651474\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w3_d300_sg1\\w2v_s0_w3_d300_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w3_d300_sg1\\w2v_s0_w3_d300_sg1.model\n",
      "Model saved: w2v_s0_w3_d300_sg1\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,3,300,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w5_d100_sg0\n",
      "Model trained: w2v_s0_w5_d100_sg0\n",
      "Fasttext training time: 1115.429569721222\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w5_d100_sg0\\w2v_s0_w5_d100_sg0.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w5_d100_sg0\\w2v_s0_w5_d100_sg0.model\n",
      "Model saved: w2v_s0_w5_d100_sg0\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,5,100,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w5_d100_sg1\n",
      "Model trained: w2v_s0_w5_d100_sg1\n",
      "Fasttext training time: 1656.9202725887299\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w5_d100_sg1\\w2v_s0_w5_d100_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w5_d100_sg1\\w2v_s0_w5_d100_sg1.model\n",
      "Model saved: w2v_s0_w5_d100_sg1\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,5,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w5_d300_sg0\n",
      "Model trained: w2v_s0_w5_d300_sg0\n",
      "Fasttext training time: 1226.0461087226868\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w5_d300_sg0\\w2v_s0_w5_d300_sg0.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w5_d300_sg0\\w2v_s0_w5_d300_sg0.model\n",
      "Model saved: w2v_s0_w5_d300_sg0\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,5,300,0,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#w2v_train_eval(0,5,300,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w10_d100_sg1\n",
      "Model trained: w2v_s0_w10_d100_sg1\n",
      "Fasttext training time: 1375.4759013652802\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w10_d100_sg1\\w2v_s0_w10_d100_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w10_d100_sg1\\w2v_s0_w10_d100_sg1.model\n",
      "Model saved: w2v_s0_w10_d100_sg1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-167cdfe87427>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw2v_train_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0manalogies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-363c616e6c4e>\u001b[0m in \u001b[0;36mw2v_train_eval\u001b[1;34m(small, window, size, sg, analogies)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msave_model_w2v\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#eval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mevaluate_word_analogies2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0manalogies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mevaluate_word_analogies2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0manalogies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mevaluate_word_analogies2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0manalogies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,10,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w10_d100_sg1\\w2v_s0_w10_d100_sg1.model\n",
      "Model loaded: w2v_s0_w10_d100_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.38095238095238093\n",
      "evalScoreT3: 0.4523809523809524\n",
      "mean_sim:  0.7921801585900156\n",
      "mean_top:  1.263157894736842\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.38095238095238093\n",
      "evalScoreT5: 0.47619047619047616\n",
      "mean_sim:  0.7875229209661484\n",
      "mean_top:  1.4\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.38095238095238093\n",
      "evalScoreT10: 0.5714285714285714\n",
      "mean_sim:  0.7708047280708948\n",
      "mean_top:  2.3333333333333335\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "w2v_load_eval(0,10,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w15_d100_sg1\n",
      "Model trained: w2v_s0_w15_d100_sg1\n",
      "Fasttext training time: 1727.2781298160553\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w15_d100_sg1\\w2v_s0_w15_d100_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w15_d100_sg1\\w2v_s0_w15_d100_sg1.model\n",
      "Model saved: w2v_s0_w15_d100_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.42857142857142855\n",
      "evalScoreT3: 0.4523809523809524\n",
      "mean_sim:  0.8070851878116005\n",
      "mean_top:  1.1578947368421053\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.42857142857142855\n",
      "evalScoreT5: 0.5\n",
      "mean_sim:  0.7963615145002093\n",
      "mean_top:  1.4761904761904763\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.42857142857142855\n",
      "evalScoreT10: 0.5714285714285714\n",
      "mean_sim:  0.787410298983256\n",
      "mean_top:  2.2083333333333335\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,15,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w20_d100_sg1\n",
      "Model trained: w2v_s0_w20_d100_sg1\n",
      "Fasttext training time: 1984.7928166389465\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w20_d100_sg1\\w2v_s0_w20_d100_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w20_d100_sg1\\w2v_s0_w20_d100_sg1.model\n",
      "Model saved: w2v_s0_w20_d100_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.40476190476190477\n",
      "evalScoreT3: 0.4523809523809524\n",
      "mean_sim:  0.793669509260278\n",
      "mean_top:  1.105263157894737\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.40476190476190477\n",
      "evalScoreT5: 0.47619047619047616\n",
      "mean_sim:  0.794109097123146\n",
      "mean_top:  1.25\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.40476190476190477\n",
      "evalScoreT10: 0.5238095238095238\n",
      "mean_sim:  0.7853280793536793\n",
      "mean_top:  1.8181818181818181\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,20,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w10_d300_sg1\n",
      "Model trained: w2v_s0_w10_d300_sg1\n",
      "Fasttext training time: 2053.113043785095\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w10_d300_sg1\\w2v_s0_w10_d300_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w10_d300_sg1\\w2v_s0_w10_d300_sg1.model\n",
      "Model saved: w2v_s0_w10_d300_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.40476190476190477\n",
      "evalScoreT3: 0.4523809523809524\n",
      "mean_sim:  0.6572419687321311\n",
      "mean_top:  1.1578947368421053\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.40476190476190477\n",
      "evalScoreT5: 0.5238095238095238\n",
      "mean_sim:  0.6435714336958799\n",
      "mean_top:  1.6363636363636365\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.40476190476190477\n",
      "evalScoreT10: 0.5714285714285714\n",
      "mean_sim:  0.6346511021256447\n",
      "mean_top:  2.2916666666666665\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,10,300,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w25_d100_sg1\n",
      "Model trained: w2v_s0_w25_d100_sg1\n",
      "Fasttext training time: 2786.4249250888824\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w25_d100_sg1\\w2v_s0_w25_d100_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w25_d100_sg1\\w2v_s0_w25_d100_sg1.model\n",
      "Model saved: w2v_s0_w25_d100_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.4523809523809524\n",
      "evalScoreT3: 0.4523809523809524\n",
      "mean_sim:  0.7898313559983906\n",
      "mean_top:  1.0526315789473684\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.4523809523809524\n",
      "evalScoreT5: 0.47619047619047616\n",
      "mean_sim:  0.7903501570224762\n",
      "mean_top:  1.25\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.4523809523809524\n",
      "evalScoreT10: 0.47619047619047616\n",
      "mean_sim:  0.7903501570224762\n",
      "mean_top:  1.25\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,25,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w30_d100_sg1\n",
      "Model trained: w2v_s0_w30_d100_sg1\n",
      "Fasttext training time: 3158.821650505066\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w30_d100_sg1\\w2v_s0_w30_d100_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w30_d100_sg1\\w2v_s0_w30_d100_sg1.model\n",
      "Model saved: w2v_s0_w30_d100_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.38095238095238093\n",
      "evalScoreT3: 0.42857142857142855\n",
      "mean_sim:  0.7875840697023604\n",
      "mean_top:  1.2222222222222223\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.38095238095238093\n",
      "evalScoreT5: 0.4523809523809524\n",
      "mean_sim:  0.7817418355690805\n",
      "mean_top:  1.368421052631579\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.38095238095238093\n",
      "evalScoreT10: 0.5238095238095238\n",
      "mean_sim:  0.7726939781145616\n",
      "mean_top:  2.227272727272727\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,30,100,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w15_d200_sg1\n",
      "Model trained: w2v_s0_w15_d200_sg1\n",
      "Fasttext training time: 2951.1605718135834\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w15_d200_sg1\\w2v_s0_w15_d200_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w15_d200_sg1\\w2v_s0_w15_d200_sg1.model\n",
      "Model saved: w2v_s0_w15_d200_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.42857142857142855\n",
      "evalScoreT3: 0.40476190476190477\n",
      "mean_sim:  0.7219123805270475\n",
      "mean_top:  1.0\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.42857142857142855\n",
      "evalScoreT5: 0.47619047619047616\n",
      "mean_sim:  0.7073572248220443\n",
      "mean_top:  1.5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.42857142857142855\n",
      "evalScoreT10: 0.5238095238095238\n",
      "mean_sim:  0.7037821818481792\n",
      "mean_top:  2.1363636363636362\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,15,200,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w15_d300_sg1\n",
      "Model trained: w2v_s0_w15_d300_sg1\n",
      "Fasttext training time: 3430.785088777542\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w15_d300_sg1\\w2v_s0_w15_d300_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w15_d300_sg1\\w2v_s0_w15_d300_sg1.model\n",
      "Model saved: w2v_s0_w15_d300_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.42857142857142855\n",
      "evalScoreT3: 0.4523809523809524\n",
      "mean_sim:  0.6743235242994208\n",
      "mean_top:  1.1578947368421053\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.42857142857142855\n",
      "evalScoreT5: 0.4523809523809524\n",
      "mean_sim:  0.6743235242994208\n",
      "mean_top:  1.1578947368421053\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.42857142857142855\n",
      "evalScoreT10: 0.47619047619047616\n",
      "mean_sim:  0.6690103381872177\n",
      "mean_top:  1.5\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,15,300,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w15_d50_sg1\n",
      "Model trained: w2v_s0_w15_d50_sg1\n",
      "Fasttext training time: 2167.2349922657013\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w15_d50_sg1\\w2v_s0_w15_d50_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w15_d50_sg1\\w2v_s0_w15_d50_sg1.model\n",
      "Model saved: w2v_s0_w15_d50_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.3333333333333333\n",
      "evalScoreT3: 0.40476190476190477\n",
      "mean_sim:  0.8560775728786693\n",
      "mean_top:  1.1764705882352942\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.3333333333333333\n",
      "evalScoreT5: 0.47619047619047616\n",
      "mean_sim:  0.8460548669099808\n",
      "mean_top:  1.7\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.3333333333333333\n",
      "evalScoreT10: 0.5238095238095238\n",
      "mean_sim:  0.8376778933134946\n",
      "mean_top:  2.4545454545454546\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,15,50,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w5_d50_sg1\n",
      "Model trained: w2v_s0_w5_d50_sg1\n",
      "Fasttext training time: 944.9098114967346\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w5_d50_sg1\\w2v_s0_w5_d50_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w5_d50_sg1\\w2v_s0_w5_d50_sg1.model\n",
      "Model saved: w2v_s0_w5_d50_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.2619047619047619\n",
      "evalScoreT3: 0.35714285714285715\n",
      "mean_sim:  0.8724554975827535\n",
      "mean_top:  1.4\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.2619047619047619\n",
      "evalScoreT5: 0.4523809523809524\n",
      "mean_sim:  0.854242553836421\n",
      "mean_top:  2.1052631578947367\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.2619047619047619\n",
      "evalScoreT10: 0.47619047619047616\n",
      "mean_sim:  0.8518807202577591\n",
      "mean_top:  2.45\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,5,50,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w5_d200_sg1\n",
      "Model trained: w2v_s0_w5_d200_sg1\n",
      "Fasttext training time: 1148.4212937355042\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w5_d200_sg1\\w2v_s0_w5_d200_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w5_d200_sg1\\w2v_s0_w5_d200_sg1.model\n",
      "Model saved: w2v_s0_w5_d200_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.30952380952380953\n",
      "evalScoreT3: 0.42857142857142855\n",
      "mean_sim:  0.6983287533124288\n",
      "mean_top:  1.4444444444444444\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.30952380952380953\n",
      "evalScoreT5: 0.5238095238095238\n",
      "mean_sim:  0.6858843104405836\n",
      "mean_top:  1.9545454545454546\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.30952380952380953\n",
      "evalScoreT10: 0.5714285714285714\n",
      "mean_sim:  0.6775408635536829\n",
      "mean_top:  2.4166666666666665\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,5,200,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w5_d400_sg1\n",
      "Model trained: w2v_s0_w5_d400_sg1\n",
      "Fasttext training time: 2140.53084897995\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w5_d400_sg1\\w2v_s0_w5_d400_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w5_d400_sg1\\w2v_s0_w5_d400_sg1.model\n",
      "Model saved: w2v_s0_w5_d400_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.2619047619047619\n",
      "evalScoreT3: 0.35714285714285715\n",
      "mean_sim:  0.6152929107348124\n",
      "mean_top:  1.3333333333333333\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.2619047619047619\n",
      "evalScoreT5: 0.42857142857142855\n",
      "mean_sim:  0.6034082637892829\n",
      "mean_top:  1.8888888888888888\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.2619047619047619\n",
      "evalScoreT10: 0.5\n",
      "mean_sim:  0.5961940515609014\n",
      "mean_top:  2.619047619047619\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,5,400,1,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training: w2v_s0_w5_d500_sg1\n",
      "Model trained: w2v_s0_w5_d500_sg1\n",
      "Fasttext training time: 3052.3342111110687\n",
      "D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w5_d500_sg1\\w2v_s0_w5_d500_sg1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\gensim_w2v\\w2v_s0_w5_d500_sg1\\w2v_s0_w5_d500_sg1.model\n",
      "Model saved: w2v_s0_w5_d500_sg1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.2857142857142857\n",
      "evalScoreT3: 0.40476190476190477\n",
      "mean_sim:  0.5845430633601021\n",
      "mean_top:  1.5294117647058822\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.2857142857142857\n",
      "evalScoreT5: 0.4523809523809524\n",
      "mean_sim:  0.5750521076352972\n",
      "mean_top:  1.8421052631578947\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  60.747663551401864\n",
      "evalScoreT1: 0.2857142857142857\n",
      "evalScoreT10: 0.5\n",
      "mean_sim:  0.5704353111130851\n",
      "mean_top:  2.2857142857142856\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "w2v_train_eval(0,5,500,1,analogies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check vocabulary size and thevector diemsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s0_w5_d100_sg1\\ft_s0_w5_d100_sg1.model\n",
      "Model loaded: ft_s0_w5_d100_sg1\n"
     ]
    }
   ],
   "source": [
    "modelName,model=load_model(0,5,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ft_s0_w5_d100_sg1\n",
      "Vocabulary size 695675\n",
      "Word vector length: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Model: \"+modelName)\n",
    "print(\"Vocabulary size\", len(list(model.wv.vocab.keys())))\n",
    "print(\"Word vector length:\", len(model.wv[\"Mann\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\KlaraRuanQian\\Desktop\\BA\\german_legal_WE\\WEs\\gensim_fasttext\\ft_s1_w5_d100_sg1\\ft_s1_w5_d100_sg1.model\n",
      "Model loaded: ft_s1_w5_d100_sg1\n"
     ]
    }
   ],
   "source": [
    "modelName,model=load_model(1,5,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ft_s1_w5_d100_sg1\n",
      "Vocabulary size 282731\n",
      "Word vector length: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Model: \"+modelName)\n",
    "print(\"Vocabulary size\", len(list(model.wv.vocab.keys())))\n",
    "print(\"Word vector length:\", len(model.wv[\"Mann\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.fasttext.FastText"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.keyedvectors.FastTextKeyedVectors"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_vsd(modelName,model):\n",
    "    print(\"Vocabulary size\", len(list(model.wv.vocab.keys())))\n",
    "    print(\"Word vector length:\", len(model.wv[\"Mann\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## continue training prtrained models on legal corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pt_ft_d300_ky = FastText.load_fasttext_format(modelPath4,full_model=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
