{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.ky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelD1=\"fasttext_pretrained\\\\de\\\\de.bin\"\n",
    "modelName1=\"pt_ft_d300_ky\"\n",
    "modelPath1 = os.getcwd()+\"\\\\WEs\\\\\"+modelD1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the pretrained model\n",
      "Loading done\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading the pretrained model\")\n",
    "pt_model1 =  FastText.load_fasttext_format(modelPath1,full_model=True)\n",
    "print(\"Loading done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_model1.vocabulary.min_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58114"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pt_model1.wv.vectors_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_basemodel_info(modelPath,model):\n",
    "    print(\"###modelPath: \", modelPath)\n",
    "    print(\"window: \",model.window)\n",
    "    print(\"embed size: \",len(model.wv[\"mann\"]))\n",
    "    print(\"sg: \"  , model.sg)\n",
    "    print(\"epochs: \", model.epochs)\n",
    "    print(\"min_count: \",model.vocabulary.min_count)\n",
    "    print(\"negative sampling: \", model.negative)\n",
    "    print(\"min_n:\",model.min_n)\n",
    "    print(\"max_n:\",model.max_n)\n",
    "    print(\"Vocabulary sie: \",len(model.wv.vectors_vocab))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###modelPath:  D:\\german_legal_WE\\WEs\\fasttext_pretrained\\de\\de.bin\n",
      "window:  5\n",
      "embed size:  300\n",
      "sg:  1\n",
      "epochs:  20\n",
      "min_count:  152\n",
      "negative sampling:  5\n",
      "min_n: 3\n",
      "max_n: 6\n",
      "Vocabulary sie:  58114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `min_n` (Attribute will be removed in 4.0.0, use wv.min_n instead).\n",
      "  if __name__ == '__main__':\n",
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `max_n` (Attribute will be removed in 4.0.0, use wv.max_n instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "print_basemodel_info(modelPath1, pt_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the small corpus\n",
      "Total examples: 924240\n",
      "Model training: pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc152\n",
      "Model training: pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc152\n",
      "Model trained: pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc152\n",
      "Fasttext training time: 324.8094356060028\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc152\\pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc152.model\n",
      "Model saved: pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc152\n",
      "evaluating T3\n",
      "d4u:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2351: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.6363636363636364\n",
      "evalScoreT3: 1.0\n",
      "mean_sim: 0.5719551118937406\n",
      "mean_top: 1.4545454545454546\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.6363636363636364\n",
      "evalScoreT5: 1.0\n",
      "mean_sim: 0.5719551118937406\n",
      "mean_top: 1.4545454545454546\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.6363636363636364\n",
      "evalScoreT10: 1.0\n",
      "mean_sim: 0.5719551118937406\n",
      "mean_top: 1.4545454545454546\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.06542056074766354\n",
      "evalScoreT3: 0.102803738317757\n",
      "mean_sim: 0.5719551118937406\n",
      "mean_top: 1.4545454545454546\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.06542056074766354\n",
      "evalScoreT5: 0.102803738317757\n",
      "mean_sim: 0.5719551118937406\n",
      "mean_top: 1.4545454545454546\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.06542056074766354\n",
      "evalScoreT10: 0.102803738317757\n",
      "mean_sim: 0.5719551118937406\n",
      "mean_top: 1.4545454545454546\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName1,pt_model1,1,5,300,1,5,152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the huge corpus\n",
      "Total examples: 4621219\n",
      "Model training: pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc152\n",
      "Model training: pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc152\n",
      "Model trained: pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc152\n",
      "Fasttext training time: 4018.491763830185\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc152\\pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc152.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc152\\pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc152.model\n",
      "Model saved: pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc152\n",
      "evaluating T3\n",
      "d4u:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2351: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.36363636363636365\n",
      "evalScoreT3: 0.7272727272727273\n",
      "mean_sim: 0.6288688033819199\n",
      "mean_top: 1.5\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.36363636363636365\n",
      "evalScoreT5: 0.8181818181818182\n",
      "mean_sim: 0.6144474281205071\n",
      "mean_top: 1.8888888888888888\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.36363636363636365\n",
      "evalScoreT10: 1.0\n",
      "mean_sim: 0.5955773375251077\n",
      "mean_top: 2.6363636363636362\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT3: 0.07476635514018691\n",
      "mean_sim: 0.6288688033819199\n",
      "mean_top: 1.5\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT5: 0.08411214953271028\n",
      "mean_sim: 0.6144474281205071\n",
      "mean_top: 1.8888888888888888\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT10: 0.102803738317757\n",
      "mean_sim: 0.5955773375251077\n",
      "mean_top: 2.6363636363636362\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName1,pt_model1,0,5,300,1,5,152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the small corpus\n",
      "Total examples: 924240\n",
      "Model training: pt_ft_d300_ky_legalC1_w5_d300_sg0_epochs5_mc1\n",
      "Model training: pt_ft_d300_ky_legalC1_w5_d300_sg0_epochs5_mc1\n",
      "Model trained: pt_ft_d300_ky_legalC1_w5_d300_sg0_epochs5_mc1\n",
      "Fasttext training time: 580.6496076583862\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC1_w5_d300_sg0_epochs5_mc1\\pt_ft_d300_ky_legalC1_w5_d300_sg0_epochs5_mc1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC1_w5_d300_sg0_epochs5_mc1\\pt_ft_d300_ky_legalC1_w5_d300_sg0_epochs5_mc1.model\n",
      "Model saved: pt_ft_d300_ky_legalC1_w5_d300_sg0_epochs5_mc1\n",
      "evaluating T3\n",
      "d4u:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2351: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.2727272727272727\n",
      "evalScoreT3: 1.0\n",
      "mean_sim: 0.5809349634430625\n",
      "mean_top: 2.090909090909091\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.2727272727272727\n",
      "evalScoreT5: 1.0\n",
      "mean_sim: 0.5809349634430625\n",
      "mean_top: 2.090909090909091\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.2727272727272727\n",
      "evalScoreT10: 1.0\n",
      "mean_sim: 0.5809349634430625\n",
      "mean_top: 2.090909090909091\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName1,pt_model1,1,5,300,0,5,1)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the small corpus\n",
      "Total examples: 924240\n",
      "Model training: pt_ft_d300_ky_legalC1_w3_d300_sg1_epochs5_mc1\n",
      "Model training: pt_ft_d300_ky_legalC1_w3_d300_sg1_epochs5_mc1\n",
      "Model trained: pt_ft_d300_ky_legalC1_w3_d300_sg1_epochs5_mc1\n",
      "Fasttext training time: 390.0156099796295\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC1_w3_d300_sg1_epochs5_mc1\\pt_ft_d300_ky_legalC1_w3_d300_sg1_epochs5_mc1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC1_w3_d300_sg1_epochs5_mc1\\pt_ft_d300_ky_legalC1_w3_d300_sg1_epochs5_mc1.model\n",
      "Model saved: pt_ft_d300_ky_legalC1_w3_d300_sg1_epochs5_mc1\n",
      "evaluating T3\n",
      "d4u:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2351: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.18181818181818182\n",
      "evalScoreT3: 0.9090909090909091\n",
      "mean_sim: 0.546697610616684\n",
      "mean_top: 2.2\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.18181818181818182\n",
      "evalScoreT5: 1.0\n",
      "mean_sim: 0.5417570986530997\n",
      "mean_top: 2.4545454545454546\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.18181818181818182\n",
      "evalScoreT10: 1.0\n",
      "mean_sim: 0.5417570986530997\n",
      "mean_top: 2.4545454545454546\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName1,pt_model1,1,3,300,1,5,1)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the huge corpus\n",
      "Total examples: 4621219\n",
      "Model training: pt_ft_d300_ky_legalC0_w3_d300_sg1_epochs5_mc1\n",
      "Model training: pt_ft_d300_ky_legalC0_w3_d300_sg1_epochs5_mc1\n",
      "Model trained: pt_ft_d300_ky_legalC0_w3_d300_sg1_epochs5_mc1\n",
      "Fasttext training time: 3715.9903881549835\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC0_w3_d300_sg1_epochs5_mc1\\pt_ft_d300_ky_legalC0_w3_d300_sg1_epochs5_mc1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC0_w3_d300_sg1_epochs5_mc1\\pt_ft_d300_ky_legalC0_w3_d300_sg1_epochs5_mc1.model\n",
      "Model saved: pt_ft_d300_ky_legalC0_w3_d300_sg1_epochs5_mc1\n",
      "evaluating T3\n",
      "d4u:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2351: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.2727272727272727\n",
      "evalScoreT3: 0.7272727272727273\n",
      "mean_sim: 0.6012379005551338\n",
      "mean_top: 1.625\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.2727272727272727\n",
      "evalScoreT5: 0.7272727272727273\n",
      "mean_sim: 0.6012379005551338\n",
      "mean_top: 1.625\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.2727272727272727\n",
      "evalScoreT10: 0.8181818181818182\n",
      "mean_sim: 0.590656922923194\n",
      "mean_top: 2.4444444444444446\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName1,pt_model1,0,3,300,1,5,1)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the small corpus\n",
      "Total examples: 924240\n",
      "Model training: pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs15_mc1\n",
      "Model training: pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs15_mc1\n",
      "Model trained: pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs15_mc1\n",
      "Fasttext training time: 1063.7720713615417\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs15_mc1\\pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs15_mc1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs15_mc1\\pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs15_mc1.model\n",
      "Model saved: pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs15_mc1\n",
      "evaluating T3\n",
      "d4u:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2351: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.18181818181818182\n",
      "evalScoreT3: 0.7272727272727273\n",
      "mean_sim: 0.5402775220572948\n",
      "mean_top: 1.75\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.18181818181818182\n",
      "evalScoreT5: 0.9090909090909091\n",
      "mean_sim: 0.5152879983186722\n",
      "mean_top: 2.4\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.18181818181818182\n",
      "evalScoreT10: 1.0\n",
      "mean_sim: 0.5074524473060261\n",
      "mean_top: 2.8181818181818183\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName1,pt_model1,1,5,300,1,15,1)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the huge corpus\n",
      "Total examples: 4621219\n",
      "Model training: pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs15_mc1\n",
      "Model training: pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs15_mc1\n",
      "Model trained: pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs15_mc1\n",
      "Fasttext training time: 10029.475875139236\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs15_mc1\\pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs15_mc1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs15_mc1\\pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs15_mc1.model\n",
      "Model saved: pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs15_mc1\n",
      "evaluating T3\n",
      "d4u:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2351: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.45454545454545453\n",
      "evalScoreT3: 0.6363636363636364\n",
      "mean_sim: 0.5828703045845032\n",
      "mean_top: 1.2857142857142858\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.45454545454545453\n",
      "evalScoreT5: 0.6363636363636364\n",
      "mean_sim: 0.5828703045845032\n",
      "mean_top: 1.2857142857142858\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.45454545454545453\n",
      "evalScoreT10: 0.8181818181818182\n",
      "mean_sim: 0.5517880651685927\n",
      "mean_top: 2.5555555555555554\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName1,pt_model1,0,5,300,1,15,1)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the small corpus\n",
      "Total examples: 924240\n",
      "Model training: pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc50\n",
      "Model training: pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc50\n",
      "Model trained: pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc50\n",
      "Fasttext training time: 361.5533330440521\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc50\\pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc50.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc50\\pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc50.model\n",
      "Model saved: pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc50\n",
      "evaluating T3\n",
      "d4u:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2351: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.36363636363636365\n",
      "evalScoreT3: 0.8181818181818182\n",
      "mean_sim: 0.5289685163233016\n",
      "mean_top: 1.6666666666666667\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.36363636363636365\n",
      "evalScoreT5: 1.0\n",
      "mean_sim: 0.510177956386046\n",
      "mean_top: 2.272727272727273\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.36363636363636365\n",
      "evalScoreT10: 1.0\n",
      "mean_sim: 0.510177956386046\n",
      "mean_top: 2.272727272727273\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName1,pt_model1,1,5,300,1,5,50)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc50\\pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc50.model\n",
      "Model loaded: pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc50\n",
      "###modelPath:  pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc50\n",
      "window:  5\n",
      "embed size:  300\n",
      "sg:  1\n",
      "epochs:  5\n",
      "min_count:  152\n",
      "negative sampling:  5\n",
      "min_n: 3\n",
      "max_n: 6\n",
      "Vocabulary sie:  58114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `min_n` (Attribute will be removed in 4.0.0, use wv.min_n instead).\n",
      "  if __name__ == '__main__':\n",
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `max_n` (Attribute will be removed in 4.0.0, use wv.max_n instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "n,model=load_model(\"pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc50\")\n",
    "print_basemodel_info(n,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the huge corpus\n",
      "Total examples: 4621219\n",
      "Model training: pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc50\n",
      "Model training: pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc50\n",
      "Model trained: pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc50\n",
      "Fasttext training time: 2206.678754091263\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc50\\pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc50.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc50\\pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc50.model\n",
      "Model saved: pt_ft_d300_ky_legalC0_w5_d300_sg1_epochs5_mc50\n",
      "evaluating T3\n",
      "d4u:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2351: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.5454545454545454\n",
      "evalScoreT3: 0.6363636363636364\n",
      "mean_sim: 0.5765126688139779\n",
      "mean_top: 1.1428571428571428\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.5454545454545454\n",
      "evalScoreT5: 0.6363636363636364\n",
      "mean_sim: 0.5765126688139779\n",
      "mean_top: 1.1428571428571428\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.5454545454545454\n",
      "evalScoreT10: 0.8181818181818182\n",
      "mean_sim: 0.542621397309833\n",
      "mean_top: 2.7777777777777777\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName1,pt_model1,0,5,300,1,5,50)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the huge corpus\n",
      "Total examples: 4621219\n",
      "Model training: pt_ft_d300_ky_legalC0_w10_d300_sg1_epochs15_mc50\n",
      "Model training: pt_ft_d300_ky_legalC0_w10_d300_sg1_epochs15_mc50\n",
      "Model trained: pt_ft_d300_ky_legalC0_w10_d300_sg1_epochs15_mc50\n",
      "Fasttext training time: 6836.79487490654\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC0_w10_d300_sg1_epochs15_mc50\\pt_ft_d300_ky_legalC0_w10_d300_sg1_epochs15_mc50.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC0_w10_d300_sg1_epochs15_mc50\\pt_ft_d300_ky_legalC0_w10_d300_sg1_epochs15_mc50.model\n",
      "Model saved: pt_ft_d300_ky_legalC0_w10_d300_sg1_epochs15_mc50\n",
      "evaluating T3\n",
      "d4u:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2351: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.6363636363636364\n",
      "evalScoreT3: 0.6363636363636364\n",
      "mean_sim: 0.5617066536630902\n",
      "mean_top: 1.0\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.6363636363636364\n",
      "evalScoreT5: 0.7272727272727273\n",
      "mean_sim: 0.5437800139188766\n",
      "mean_top: 1.375\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.6363636363636364\n",
      "evalScoreT10: 0.8181818181818182\n",
      "mean_sim: 0.5345200002193451\n",
      "mean_top: 2.0\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName1,pt_model1,0,10,300,1,15,50)#!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the huge corpus\n",
      "Total examples: 4621219\n",
      "Model training: pt_ft_d300_ky_legalC0_w10_d300_sg1_epochs20_mc50\n",
      "Model training: pt_ft_d300_ky_legalC0_w10_d300_sg1_epochs20_mc50\n",
      "Model trained: pt_ft_d300_ky_legalC0_w10_d300_sg1_epochs20_mc50\n",
      "Fasttext training time: 15513.208807229996\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC0_w10_d300_sg1_epochs20_mc50\\pt_ft_d300_ky_legalC0_w10_d300_sg1_epochs20_mc50.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC0_w10_d300_sg1_epochs20_mc50\\pt_ft_d300_ky_legalC0_w10_d300_sg1_epochs20_mc50.model\n",
      "Model saved: pt_ft_d300_ky_legalC0_w10_d300_sg1_epochs20_mc50\n",
      "evaluating T3\n",
      "d4u:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2351: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.5454545454545454\n",
      "evalScoreT3: 0.6363636363636364\n",
      "mean_sim: 0.5592533349990845\n",
      "mean_top: 1.1428571428571428\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.5454545454545454\n",
      "evalScoreT5: 0.6363636363636364\n",
      "mean_sim: 0.5592533349990845\n",
      "mean_top: 1.1428571428571428\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  89.7196261682243\n",
      "evalScoreT1:  0.5454545454545454\n",
      "evalScoreT10: 0.8181818181818182\n",
      "mean_sim: 0.5311438043912252\n",
      "mean_top: 2.6666666666666665\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName1,pt_model1,0,10,300,1,20,50)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ft_train_eval(modelName1,pt_model1,MyIterSmall(),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ft_load_eval(modelName1,analogies,1,d4u=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ft_train_eval(modelName1,pt_model1,MyIterHuge(),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ft_load_eval(modelName1,analogies,0,d4u=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ft_train_eval(modelName,pt_model,MyIterHuge(),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pt_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelD2=\"fasttext_pretrained\\\\facebook\\\\cc.de.300.bin\"\n",
    "modelName2=\"pt_ft_d300_fb\"\n",
    "modelPath2 = os.getcwd()+\"\\\\WEs\\\\\"+modelD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the pretrained modelD:\\german_legal_WE\\WEs\\fasttext_pretrained\\facebook\\cc.de.300.bin\n",
      "Loading done\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading the pretrained model\"+modelPath2)\n",
    "pt_model2 =  FastText.load_fasttext_format(modelPath2,full_model=True)\n",
    "print(\"Loading done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###modelPath:  D:\\german_legal_WE\\WEs\\fasttext_pretrained\\facebook\\cc.de.300.bin\n",
      "window:  5\n",
      "embed size:  300\n",
      "sg:  0\n",
      "epochs:  1\n",
      "min_count:  5\n",
      "negative sampling:  10\n",
      "min_n: 5\n",
      "max_n: 5\n",
      "Vocabulary sie:  2000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `min_n` (Attribute will be removed in 4.0.0, use wv.min_n instead).\n",
      "  if __name__ == '__main__':\n",
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `max_n` (Attribute will be removed in 4.0.0, use wv.max_n instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "print_basemodel_info(modelPath2, pt_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the small corpus\n",
      "Total examples: 924240\n",
      "Model training: pt_ft_d300_fb_legalC1_w5_d300_sg1_epochs5_mc1\n",
      "Model training: pt_ft_d300_fb_legalC1_w5_d300_sg1_epochs5_mc1\n",
      "Model trained: pt_ft_d300_fb_legalC1_w5_d300_sg1_epochs5_mc1\n",
      "Fasttext training time: 240.16040921211243\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC1_w5_d300_sg1_epochs5_mc1\\pt_ft_d300_fb_legalC1_w5_d300_sg1_epochs5_mc1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC1_w5_d300_sg1_epochs5_mc1\\pt_ft_d300_fb_legalC1_w5_d300_sg1_epochs5_mc1.model\n",
      "Model saved: pt_ft_d300_fb_legalC1_w5_d300_sg1_epochs5_mc1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName2,pt_model2,1,5,300,1,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the small corpus\n",
      "Total examples: 924240\n",
      "Model training: pt_ft_d300_fb_legalC1_w5_d300_sg1_epochs10_mc1\n",
      "Model training: pt_ft_d300_fb_legalC1_w5_d300_sg1_epochs10_mc1\n",
      "Model trained: pt_ft_d300_fb_legalC1_w5_d300_sg1_epochs10_mc1\n",
      "Fasttext training time: 386.0594115257263\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC1_w5_d300_sg1_epochs10_mc1\\pt_ft_d300_fb_legalC1_w5_d300_sg1_epochs10_mc1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC1_w5_d300_sg1_epochs10_mc1\\pt_ft_d300_fb_legalC1_w5_d300_sg1_epochs10_mc1.model\n",
      "Model saved: pt_ft_d300_fb_legalC1_w5_d300_sg1_epochs10_mc1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName2,pt_model2,1,5,300,1,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the huge corpus\n",
      "Total examples: 4621219\n",
      "Model training: pt_ft_d300_fb_legalC0_w5_d300_sg1_epochs5_mc1\n",
      "Model training: pt_ft_d300_fb_legalC0_w5_d300_sg1_epochs5_mc1\n",
      "Model trained: pt_ft_d300_fb_legalC0_w5_d300_sg1_epochs5_mc1\n",
      "Fasttext training time: 994.6004526615143\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC0_w5_d300_sg1_epochs5_mc1\\pt_ft_d300_fb_legalC0_w5_d300_sg1_epochs5_mc1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC0_w5_d300_sg1_epochs5_mc1\\pt_ft_d300_fb_legalC0_w5_d300_sg1_epochs5_mc1.model\n",
      "Model saved: pt_ft_d300_fb_legalC0_w5_d300_sg1_epochs5_mc1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName2,pt_model2,0,5,300,1,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the huge corpus\n",
      "Total examples: 4621219\n",
      "Model training: pt_ft_d300_fb_legalC0_w5_d300_sg1_epochs10_mc1\n",
      "Model training: pt_ft_d300_fb_legalC0_w5_d300_sg1_epochs10_mc1\n",
      "Model trained: pt_ft_d300_fb_legalC0_w5_d300_sg1_epochs10_mc1\n",
      "Fasttext training time: 1840.286934375763\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC0_w5_d300_sg1_epochs10_mc1\\pt_ft_d300_fb_legalC0_w5_d300_sg1_epochs10_mc1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC0_w5_d300_sg1_epochs10_mc1\\pt_ft_d300_fb_legalC0_w5_d300_sg1_epochs10_mc1.model\n",
      "Model saved: pt_ft_d300_fb_legalC0_w5_d300_sg1_epochs10_mc1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName2,pt_model2,0,5,300,1,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ft_train_eval(modelName2,pt_model2,MyIterSmall(),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ft_load_eval(modelName2,analogies,1,d4u=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ft_train_eval(modelName2,pt_model2,MyIterHuge(),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ft_load_eval(modelName2,analogies,0,d4u=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.30434782608695654\n",
      "evalScoreT3: 0.6521739130434783\n",
      "mean_sim: 0.7666202982266744\n",
      "mean_top: 1.8\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.30434782608695654\n",
      "evalScoreT5: 0.782608695652174\n",
      "mean_sim: 0.7607891625828214\n",
      "mean_top: 2.2222222222222223\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.30434782608695654\n",
      "evalScoreT10: 0.9130434782608695\n",
      "mean_sim: 0.7549702723821005\n",
      "mean_top: 2.857142857142857\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.06542056074766354\n",
      "evalScoreT3: 0.14018691588785046\n",
      "mean_sim: 0.7666202982266744\n",
      "mean_top: 1.8\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.06542056074766354\n",
      "evalScoreT5: 0.16822429906542055\n",
      "mean_sim: 0.7607891625828214\n",
      "mean_top: 2.2222222222222223\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.06542056074766354\n",
      "evalScoreT10: 0.19626168224299065\n",
      "mean_sim: 0.7549702723821005\n",
      "mean_top: 2.857142857142857\n",
      "evaluating done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06542056074766354,\n",
       " 0.7549702723821005,\n",
       " 2.857142857142857,\n",
       " 0.19626168224299065,\n",
       " [{'section': 'Vertreter u. Vertretener',\n",
       "   'correct': [],\n",
       "   'incorrect': [('Rechtsanwalt', 'Mandant', 'Vertreter', 'Vertretener'),\n",
       "    ('Rechtsanwalt', 'Mandant', 'Kommissionär', 'Kommittent'),\n",
       "    ('Vertreter', 'Vertretener', 'Kommissionär', 'Kommittent')]},\n",
       "  {'section': 'personenverhältnisse',\n",
       "   'correct': [],\n",
       "   'incorrect': [('Eltern',\n",
       "     'Kind',\n",
       "     'Unterhaltspflichtiger',\n",
       "     'Unterhaltsberechtigter')]},\n",
       "  {'section': 'eigentum',\n",
       "   'correct': [],\n",
       "   'incorrect': [('Patentinhaber',\n",
       "     'Patent',\n",
       "     'Eigentümer',\n",
       "     'Sache',\n",
       "     'Eigenthum')]},\n",
       "  {'section': 'gläubiger u. neuer Gläubiger',\n",
       "   'correct': [],\n",
       "   'incorrect': [('Forderungsinhaber',\n",
       "     'Forderungserwerber',\n",
       "     'Zedent',\n",
       "     'Zessionar')]},\n",
       "  {'section': 'vertragpartner',\n",
       "   'correct': [('Vermieter',\n",
       "     'Mieter',\n",
       "     'Verpächter',\n",
       "     'Pächter',\n",
       "     'Pächter',\n",
       "     0.8122190237045288,\n",
       "     1),\n",
       "    ('Vermieter',\n",
       "     'Mieter',\n",
       "     'Leasinggeber',\n",
       "     'Leasingnehmer',\n",
       "     'Leasingnehmer',\n",
       "     0.7049499750137329,\n",
       "     1),\n",
       "    ('Vermieter',\n",
       "     'Mieter',\n",
       "     'Kreditgeber',\n",
       "     'Kreditnehmer',\n",
       "     'Kreditnehmer',\n",
       "     0.7466200590133667,\n",
       "     2),\n",
       "    ('Vermieter',\n",
       "     'Mieter',\n",
       "     'Auftraggeber',\n",
       "     'Auftragnehmer',\n",
       "     'Auftragnehmer',\n",
       "     0.6606576442718506,\n",
       "     7),\n",
       "    ('Vermieter',\n",
       "     'Mieter',\n",
       "     'Versicherer',\n",
       "     'Versicherungsnehmer',\n",
       "     'Versicherungsnehmer',\n",
       "     0.7564501762390137,\n",
       "     5),\n",
       "    ('Verkäufer',\n",
       "     'Käufer',\n",
       "     'Verpächter',\n",
       "     'Pächter',\n",
       "     'Pächter',\n",
       "     0.7968176603317261,\n",
       "     1),\n",
       "    ('Verkäufer',\n",
       "     'Käufer',\n",
       "     'Leasinggeber',\n",
       "     'Leasingnehmer',\n",
       "     'Leasingnehmer',\n",
       "     0.6884458065032959,\n",
       "     1),\n",
       "    ('Verkäufer',\n",
       "     'Käufer',\n",
       "     'Kreditgeber',\n",
       "     'Kreditnehmer',\n",
       "     'Kreditnehmer',\n",
       "     0.702728807926178,\n",
       "     2),\n",
       "    ('Verkäufer',\n",
       "     'Käufer',\n",
       "     'Auftraggeber',\n",
       "     'Auftragnehmer',\n",
       "     'Auftragnehmer',\n",
       "     0.6600418090820312,\n",
       "     4),\n",
       "    ('Verkäufer',\n",
       "     'Käufer',\n",
       "     'Versicherer',\n",
       "     'Versicherungsnehmer',\n",
       "     'Versicherungsnehmer',\n",
       "     0.7018328905105591,\n",
       "     3),\n",
       "    ('Verpächter',\n",
       "     'Pächter',\n",
       "     'Leasinggeber',\n",
       "     'Leasingnehmer',\n",
       "     'Leasingnehmer',\n",
       "     0.7611367702484131,\n",
       "     1),\n",
       "    ('Verpächter',\n",
       "     'Pächter',\n",
       "     'Kreditgeber',\n",
       "     'Kreditnehmer',\n",
       "     'Kreditnehmer',\n",
       "     0.7968244552612305,\n",
       "     2),\n",
       "    ('Verpächter',\n",
       "     'Pächter',\n",
       "     'Auftraggeber',\n",
       "     'Auftragnehmer',\n",
       "     'Auftragnehmer',\n",
       "     0.7221624851226807,\n",
       "     6),\n",
       "    ('Verpächter',\n",
       "     'Pächter',\n",
       "     'Versicherer',\n",
       "     'Versicherungsnehmer',\n",
       "     'Versicherungsnehmer',\n",
       "     0.777350664138794,\n",
       "     7),\n",
       "    ('Leasinggeber',\n",
       "     'Leasingnehmer',\n",
       "     'Kreditgeber',\n",
       "     'Kreditnehmer',\n",
       "     'Kreditnehmer',\n",
       "     0.866721510887146,\n",
       "     1),\n",
       "    ('Leasinggeber',\n",
       "     'Leasingnehmer',\n",
       "     'Auftraggeber',\n",
       "     'Auftragnehmer',\n",
       "     'Auftragnehmer',\n",
       "     0.8979005813598633,\n",
       "     1),\n",
       "    ('Leasinggeber',\n",
       "     'Leasingnehmer',\n",
       "     'Versicherer',\n",
       "     'Versicherungsnehmer',\n",
       "     'Versicherungsnehmer',\n",
       "     0.7828404903411865,\n",
       "     3),\n",
       "    ('Kreditgeber',\n",
       "     'Kreditnehmer',\n",
       "     'Auftraggeber',\n",
       "     'Auftragnehmer',\n",
       "     'Auftragnehmer',\n",
       "     0.7784084677696228,\n",
       "     4),\n",
       "    ('Kreditgeber',\n",
       "     'Kreditnehmer',\n",
       "     'Versicherer',\n",
       "     'Versicherungsnehmer',\n",
       "     'Versicherungsnehmer',\n",
       "     0.8049708604812622,\n",
       "     3),\n",
       "    ('Auftraggeber',\n",
       "     'Auftragnehmer',\n",
       "     'Versicherer',\n",
       "     'Versicherungsnehmer',\n",
       "     'Versicherungsnehmer',\n",
       "     0.735816478729248,\n",
       "     3)],\n",
       "   'incorrect': [('Vermieter', 'Mieter', 'Verkäufer', 'Käufer', 'Einkäufer'),\n",
       "    ('Vermieter', 'Mieter', 'Verleiher', 'Leiher'),\n",
       "    ('Vermieter', 'Mieter', 'Arbeitsgeber', 'Arbeitsnehmer'),\n",
       "    ('Vermieter', 'Mieter', 'Sicherungsgeber', 'Sicherungsnehmer'),\n",
       "    ('Vermieter', 'Mieter', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Vermieter', 'Mieter', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Vermieter', 'Mieter', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Vermieter', 'Mieter', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Verkäufer', 'Käufer', 'Verleiher', 'Leiher'),\n",
       "    ('Verkäufer', 'Käufer', 'Arbeitsgeber', 'Arbeitsnehmer'),\n",
       "    ('Verkäufer', 'Käufer', 'Sicherungsgeber', 'Sicherungsnehmer'),\n",
       "    ('Verkäufer', 'Käufer', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Verkäufer', 'Käufer', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Verkäufer', 'Käufer', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Verkäufer', 'Käufer', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Verpächter', 'Pächter', 'Verleiher', 'Leiher'),\n",
       "    ('Verpächter', 'Pächter', 'Arbeitsgeber', 'Arbeitsnehmer'),\n",
       "    ('Verpächter', 'Pächter', 'Sicherungsgeber', 'Sicherungsnehmer'),\n",
       "    ('Verpächter', 'Pächter', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Verpächter', 'Pächter', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Verpächter', 'Pächter', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Verpächter', 'Pächter', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Verleiher', 'Leiher', 'Leasinggeber', 'Leasingnehmer'),\n",
       "    ('Verleiher', 'Leiher', 'Arbeitsgeber', 'Arbeitsnehmer'),\n",
       "    ('Verleiher', 'Leiher', 'Kreditgeber', 'Kreditnehmer'),\n",
       "    ('Verleiher', 'Leiher', 'Auftraggeber', 'Auftragnehmer'),\n",
       "    ('Verleiher', 'Leiher', 'Sicherungsgeber', 'Sicherungsnehmer'),\n",
       "    ('Verleiher', 'Leiher', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Verleiher', 'Leiher', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Verleiher', 'Leiher', 'Versicherer', 'Versicherungsnehmer'),\n",
       "    ('Verleiher', 'Leiher', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Verleiher', 'Leiher', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Leasinggeber', 'Leasingnehmer', 'Arbeitsgeber', 'Arbeitsnehmer'),\n",
       "    ('Leasinggeber', 'Leasingnehmer', 'Sicherungsgeber', 'Sicherungsnehmer'),\n",
       "    ('Leasinggeber', 'Leasingnehmer', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Leasinggeber', 'Leasingnehmer', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Leasinggeber', 'Leasingnehmer', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Leasinggeber', 'Leasingnehmer', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Arbeitsgeber', 'Arbeitsnehmer', 'Kreditgeber', 'Kreditnehmer'),\n",
       "    ('Arbeitsgeber', 'Arbeitsnehmer', 'Auftraggeber', 'Auftragnehmer'),\n",
       "    ('Arbeitsgeber', 'Arbeitsnehmer', 'Sicherungsgeber', 'Sicherungsnehmer'),\n",
       "    ('Arbeitsgeber', 'Arbeitsnehmer', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Arbeitsgeber', 'Arbeitsnehmer', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Arbeitsgeber', 'Arbeitsnehmer', 'Versicherer', 'Versicherungsnehmer'),\n",
       "    ('Arbeitsgeber', 'Arbeitsnehmer', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Arbeitsgeber', 'Arbeitsnehmer', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Kreditgeber', 'Kreditnehmer', 'Sicherungsgeber', 'Sicherungsnehmer'),\n",
       "    ('Kreditgeber', 'Kreditnehmer', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Kreditgeber', 'Kreditnehmer', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Kreditgeber', 'Kreditnehmer', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Kreditgeber', 'Kreditnehmer', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Auftraggeber', 'Auftragnehmer', 'Sicherungsgeber', 'Sicherungsnehmer'),\n",
       "    ('Auftraggeber', 'Auftragnehmer', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Auftraggeber', 'Auftragnehmer', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Auftraggeber', 'Auftragnehmer', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Auftraggeber', 'Auftragnehmer', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Sicherungsgeber', 'Sicherungsnehmer', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Sicherungsgeber', 'Sicherungsnehmer', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Sicherungsgeber',\n",
       "     'Sicherungsnehmer',\n",
       "     'Versicherer',\n",
       "     'Versicherungsnehmer'),\n",
       "    ('Sicherungsgeber', 'Sicherungsnehmer', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Sicherungsgeber',\n",
       "     'Sicherungsnehmer',\n",
       "     'Hypothekar',\n",
       "     'Hypothekenschuldner'),\n",
       "    ('Verwahrer', 'Hinterleger', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Verwahrer', 'Hinterleger', 'Versicherer', 'Versicherungsnehmer'),\n",
       "    ('Verwahrer', 'Hinterleger', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Verwahrer', 'Hinterleger', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Werkunternehmer', 'Besteller', 'Versicherer', 'Versicherungsnehmer'),\n",
       "    ('Werkunternehmer', 'Besteller', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Werkunternehmer', 'Besteller', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Versicherer', 'Versicherungsnehmer', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Versicherer',\n",
       "     'Versicherungsnehmer',\n",
       "     'Hypothekar',\n",
       "     'Hypothekenschuldner'),\n",
       "    ('Arbeitsgeber', 'Gewerksschaft', 'Hypothekar', 'Hypothekenschuldner')]},\n",
       "  {'section': 'Gläubiger u. Schuldver',\n",
       "   'correct': [('Gläubiger',\n",
       "     'Schuldner',\n",
       "     'Kreditgeber',\n",
       "     'Kreditnehmer',\n",
       "     'Kreditnehmer',\n",
       "     0.6994791030883789,\n",
       "     2)],\n",
       "   'incorrect': [('Gläubiger', 'Schuldner', 'Kreditor', 'Debitor'),\n",
       "    ('Gläubiger', 'Schuldner', 'Pfandgläubiger', 'Pfandschuldner'),\n",
       "    ('Gläubiger', 'Schuldner', 'Anspruchssteller', 'Anspruchsgegner'),\n",
       "    ('Kreditgeber', 'Kreditnehmer', 'Kreditor', 'Debitor'),\n",
       "    ('Kreditgeber', 'Kreditnehmer', 'Pfandgläubiger', 'Pfandschuldner'),\n",
       "    ('Kreditgeber', 'Kreditnehmer', 'Anspruchssteller', 'Anspruchsgegner'),\n",
       "    ('Kreditor', 'Debitor', 'Pfandgläubiger', 'Pfandschuldner'),\n",
       "    ('Kreditor', 'Debitor', 'Anspruchssteller', 'Anspruchsgegner'),\n",
       "    ('Pfandgläubiger',\n",
       "     'Pfandschuldner',\n",
       "     'Anspruchssteller',\n",
       "     'Anspruchsgegner')]},\n",
       "  {'section': 'Total accuracy',\n",
       "   'correct': [('Vermieter',\n",
       "     'Mieter',\n",
       "     'Verpächter',\n",
       "     'Pächter',\n",
       "     'Pächter',\n",
       "     0.8122190237045288,\n",
       "     1),\n",
       "    ('Vermieter',\n",
       "     'Mieter',\n",
       "     'Leasinggeber',\n",
       "     'Leasingnehmer',\n",
       "     'Leasingnehmer',\n",
       "     0.7049499750137329,\n",
       "     1),\n",
       "    ('Vermieter',\n",
       "     'Mieter',\n",
       "     'Kreditgeber',\n",
       "     'Kreditnehmer',\n",
       "     'Kreditnehmer',\n",
       "     0.7466200590133667,\n",
       "     2),\n",
       "    ('Vermieter',\n",
       "     'Mieter',\n",
       "     'Auftraggeber',\n",
       "     'Auftragnehmer',\n",
       "     'Auftragnehmer',\n",
       "     0.6606576442718506,\n",
       "     7),\n",
       "    ('Vermieter',\n",
       "     'Mieter',\n",
       "     'Versicherer',\n",
       "     'Versicherungsnehmer',\n",
       "     'Versicherungsnehmer',\n",
       "     0.7564501762390137,\n",
       "     5),\n",
       "    ('Verkäufer',\n",
       "     'Käufer',\n",
       "     'Verpächter',\n",
       "     'Pächter',\n",
       "     'Pächter',\n",
       "     0.7968176603317261,\n",
       "     1),\n",
       "    ('Verkäufer',\n",
       "     'Käufer',\n",
       "     'Leasinggeber',\n",
       "     'Leasingnehmer',\n",
       "     'Leasingnehmer',\n",
       "     0.6884458065032959,\n",
       "     1),\n",
       "    ('Verkäufer',\n",
       "     'Käufer',\n",
       "     'Kreditgeber',\n",
       "     'Kreditnehmer',\n",
       "     'Kreditnehmer',\n",
       "     0.702728807926178,\n",
       "     2),\n",
       "    ('Verkäufer',\n",
       "     'Käufer',\n",
       "     'Auftraggeber',\n",
       "     'Auftragnehmer',\n",
       "     'Auftragnehmer',\n",
       "     0.6600418090820312,\n",
       "     4),\n",
       "    ('Verkäufer',\n",
       "     'Käufer',\n",
       "     'Versicherer',\n",
       "     'Versicherungsnehmer',\n",
       "     'Versicherungsnehmer',\n",
       "     0.7018328905105591,\n",
       "     3),\n",
       "    ('Verpächter',\n",
       "     'Pächter',\n",
       "     'Leasinggeber',\n",
       "     'Leasingnehmer',\n",
       "     'Leasingnehmer',\n",
       "     0.7611367702484131,\n",
       "     1),\n",
       "    ('Verpächter',\n",
       "     'Pächter',\n",
       "     'Kreditgeber',\n",
       "     'Kreditnehmer',\n",
       "     'Kreditnehmer',\n",
       "     0.7968244552612305,\n",
       "     2),\n",
       "    ('Verpächter',\n",
       "     'Pächter',\n",
       "     'Auftraggeber',\n",
       "     'Auftragnehmer',\n",
       "     'Auftragnehmer',\n",
       "     0.7221624851226807,\n",
       "     6),\n",
       "    ('Verpächter',\n",
       "     'Pächter',\n",
       "     'Versicherer',\n",
       "     'Versicherungsnehmer',\n",
       "     'Versicherungsnehmer',\n",
       "     0.777350664138794,\n",
       "     7),\n",
       "    ('Leasinggeber',\n",
       "     'Leasingnehmer',\n",
       "     'Kreditgeber',\n",
       "     'Kreditnehmer',\n",
       "     'Kreditnehmer',\n",
       "     0.866721510887146,\n",
       "     1),\n",
       "    ('Leasinggeber',\n",
       "     'Leasingnehmer',\n",
       "     'Auftraggeber',\n",
       "     'Auftragnehmer',\n",
       "     'Auftragnehmer',\n",
       "     0.8979005813598633,\n",
       "     1),\n",
       "    ('Leasinggeber',\n",
       "     'Leasingnehmer',\n",
       "     'Versicherer',\n",
       "     'Versicherungsnehmer',\n",
       "     'Versicherungsnehmer',\n",
       "     0.7828404903411865,\n",
       "     3),\n",
       "    ('Kreditgeber',\n",
       "     'Kreditnehmer',\n",
       "     'Auftraggeber',\n",
       "     'Auftragnehmer',\n",
       "     'Auftragnehmer',\n",
       "     0.7784084677696228,\n",
       "     4),\n",
       "    ('Kreditgeber',\n",
       "     'Kreditnehmer',\n",
       "     'Versicherer',\n",
       "     'Versicherungsnehmer',\n",
       "     'Versicherungsnehmer',\n",
       "     0.8049708604812622,\n",
       "     3),\n",
       "    ('Auftraggeber',\n",
       "     'Auftragnehmer',\n",
       "     'Versicherer',\n",
       "     'Versicherungsnehmer',\n",
       "     'Versicherungsnehmer',\n",
       "     0.735816478729248,\n",
       "     3),\n",
       "    ('Gläubiger',\n",
       "     'Schuldner',\n",
       "     'Kreditgeber',\n",
       "     'Kreditnehmer',\n",
       "     'Kreditnehmer',\n",
       "     0.6994791030883789,\n",
       "     2)],\n",
       "   'incorrect': [('Rechtsanwalt', 'Mandant', 'Vertreter', 'Vertretener'),\n",
       "    ('Rechtsanwalt', 'Mandant', 'Kommissionär', 'Kommittent'),\n",
       "    ('Vertreter', 'Vertretener', 'Kommissionär', 'Kommittent'),\n",
       "    ('Eltern', 'Kind', 'Unterhaltspflichtiger', 'Unterhaltsberechtigter'),\n",
       "    ('Patentinhaber', 'Patent', 'Eigentümer', 'Sache', 'Eigenthum'),\n",
       "    ('Forderungsinhaber', 'Forderungserwerber', 'Zedent', 'Zessionar'),\n",
       "    ('Vermieter', 'Mieter', 'Verkäufer', 'Käufer', 'Einkäufer'),\n",
       "    ('Vermieter', 'Mieter', 'Verleiher', 'Leiher'),\n",
       "    ('Vermieter', 'Mieter', 'Arbeitsgeber', 'Arbeitsnehmer'),\n",
       "    ('Vermieter', 'Mieter', 'Sicherungsgeber', 'Sicherungsnehmer'),\n",
       "    ('Vermieter', 'Mieter', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Vermieter', 'Mieter', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Vermieter', 'Mieter', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Vermieter', 'Mieter', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Verkäufer', 'Käufer', 'Verleiher', 'Leiher'),\n",
       "    ('Verkäufer', 'Käufer', 'Arbeitsgeber', 'Arbeitsnehmer'),\n",
       "    ('Verkäufer', 'Käufer', 'Sicherungsgeber', 'Sicherungsnehmer'),\n",
       "    ('Verkäufer', 'Käufer', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Verkäufer', 'Käufer', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Verkäufer', 'Käufer', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Verkäufer', 'Käufer', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Verpächter', 'Pächter', 'Verleiher', 'Leiher'),\n",
       "    ('Verpächter', 'Pächter', 'Arbeitsgeber', 'Arbeitsnehmer'),\n",
       "    ('Verpächter', 'Pächter', 'Sicherungsgeber', 'Sicherungsnehmer'),\n",
       "    ('Verpächter', 'Pächter', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Verpächter', 'Pächter', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Verpächter', 'Pächter', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Verpächter', 'Pächter', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Verleiher', 'Leiher', 'Leasinggeber', 'Leasingnehmer'),\n",
       "    ('Verleiher', 'Leiher', 'Arbeitsgeber', 'Arbeitsnehmer'),\n",
       "    ('Verleiher', 'Leiher', 'Kreditgeber', 'Kreditnehmer'),\n",
       "    ('Verleiher', 'Leiher', 'Auftraggeber', 'Auftragnehmer'),\n",
       "    ('Verleiher', 'Leiher', 'Sicherungsgeber', 'Sicherungsnehmer'),\n",
       "    ('Verleiher', 'Leiher', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Verleiher', 'Leiher', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Verleiher', 'Leiher', 'Versicherer', 'Versicherungsnehmer'),\n",
       "    ('Verleiher', 'Leiher', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Verleiher', 'Leiher', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Leasinggeber', 'Leasingnehmer', 'Arbeitsgeber', 'Arbeitsnehmer'),\n",
       "    ('Leasinggeber', 'Leasingnehmer', 'Sicherungsgeber', 'Sicherungsnehmer'),\n",
       "    ('Leasinggeber', 'Leasingnehmer', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Leasinggeber', 'Leasingnehmer', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Leasinggeber', 'Leasingnehmer', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Leasinggeber', 'Leasingnehmer', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Arbeitsgeber', 'Arbeitsnehmer', 'Kreditgeber', 'Kreditnehmer'),\n",
       "    ('Arbeitsgeber', 'Arbeitsnehmer', 'Auftraggeber', 'Auftragnehmer'),\n",
       "    ('Arbeitsgeber', 'Arbeitsnehmer', 'Sicherungsgeber', 'Sicherungsnehmer'),\n",
       "    ('Arbeitsgeber', 'Arbeitsnehmer', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Arbeitsgeber', 'Arbeitsnehmer', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Arbeitsgeber', 'Arbeitsnehmer', 'Versicherer', 'Versicherungsnehmer'),\n",
       "    ('Arbeitsgeber', 'Arbeitsnehmer', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Arbeitsgeber', 'Arbeitsnehmer', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Kreditgeber', 'Kreditnehmer', 'Sicherungsgeber', 'Sicherungsnehmer'),\n",
       "    ('Kreditgeber', 'Kreditnehmer', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Kreditgeber', 'Kreditnehmer', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Kreditgeber', 'Kreditnehmer', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Kreditgeber', 'Kreditnehmer', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Auftraggeber', 'Auftragnehmer', 'Sicherungsgeber', 'Sicherungsnehmer'),\n",
       "    ('Auftraggeber', 'Auftragnehmer', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Auftraggeber', 'Auftragnehmer', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Auftraggeber', 'Auftragnehmer', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Auftraggeber', 'Auftragnehmer', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Sicherungsgeber', 'Sicherungsnehmer', 'Verwahrer', 'Hinterleger'),\n",
       "    ('Sicherungsgeber', 'Sicherungsnehmer', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Sicherungsgeber',\n",
       "     'Sicherungsnehmer',\n",
       "     'Versicherer',\n",
       "     'Versicherungsnehmer'),\n",
       "    ('Sicherungsgeber', 'Sicherungsnehmer', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Sicherungsgeber',\n",
       "     'Sicherungsnehmer',\n",
       "     'Hypothekar',\n",
       "     'Hypothekenschuldner'),\n",
       "    ('Verwahrer', 'Hinterleger', 'Werkunternehmer', 'Besteller'),\n",
       "    ('Verwahrer', 'Hinterleger', 'Versicherer', 'Versicherungsnehmer'),\n",
       "    ('Verwahrer', 'Hinterleger', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Verwahrer', 'Hinterleger', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Werkunternehmer', 'Besteller', 'Versicherer', 'Versicherungsnehmer'),\n",
       "    ('Werkunternehmer', 'Besteller', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Werkunternehmer', 'Besteller', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Versicherer', 'Versicherungsnehmer', 'Arbeitsgeber', 'Gewerksschaft'),\n",
       "    ('Versicherer',\n",
       "     'Versicherungsnehmer',\n",
       "     'Hypothekar',\n",
       "     'Hypothekenschuldner'),\n",
       "    ('Arbeitsgeber', 'Gewerksschaft', 'Hypothekar', 'Hypothekenschuldner'),\n",
       "    ('Gläubiger', 'Schuldner', 'Kreditor', 'Debitor'),\n",
       "    ('Gläubiger', 'Schuldner', 'Pfandgläubiger', 'Pfandschuldner'),\n",
       "    ('Gläubiger', 'Schuldner', 'Anspruchssteller', 'Anspruchsgegner'),\n",
       "    ('Kreditgeber', 'Kreditnehmer', 'Kreditor', 'Debitor'),\n",
       "    ('Kreditgeber', 'Kreditnehmer', 'Pfandgläubiger', 'Pfandschuldner'),\n",
       "    ('Kreditgeber', 'Kreditnehmer', 'Anspruchssteller', 'Anspruchsgegner'),\n",
       "    ('Kreditor', 'Debitor', 'Pfandgläubiger', 'Pfandschuldner'),\n",
       "    ('Kreditor', 'Debitor', 'Anspruchssteller', 'Anspruchsgegner'),\n",
       "    ('Pfandgläubiger',\n",
       "     'Pfandschuldner',\n",
       "     'Anspruchssteller',\n",
       "     'Anspruchsgegner')]}])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_word_analogies2(pt_model2.wv,modelName2,3,analogies)\n",
    "evaluate_word_analogies2(pt_model2.wv,modelName2,5,analogies)\n",
    "evaluate_word_analogies2(pt_model2.wv,modelName2,10,analogies)\n",
    "evaluate_word_analogies2(pt_model2.wv, modelName2,3,analogies,dummy4unknown=True)\n",
    "evaluate_word_analogies2(pt_model2.wv, modelName2,5,analogies,dummy4unknown=True)\n",
    "evaluate_word_analogies2(pt_model2.wv, modelName2,10,analogies,dummy4unknown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the small corpus\n",
      "Total examples: 924240\n",
      "Model training: pt_ft_d300_fb_legalC1_w5_d300_sg0_epochs10_mc5\n",
      "Model training: pt_ft_d300_fb_legalC1_w5_d300_sg0_epochs10_mc5\n",
      "Model trained: pt_ft_d300_fb_legalC1_w5_d300_sg0_epochs10_mc5\n",
      "Fasttext training time: 400.18438839912415\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC1_w5_d300_sg0_epochs10_mc5\\pt_ft_d300_fb_legalC1_w5_d300_sg0_epochs10_mc5.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC1_w5_d300_sg0_epochs10_mc5\\pt_ft_d300_fb_legalC1_w5_d300_sg0_epochs10_mc5.model\n",
      "Model saved: pt_ft_d300_fb_legalC1_w5_d300_sg0_epochs10_mc5\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT3: 0.5217391304347826\n",
      "mean_sim: 0.7492195218801498\n",
      "mean_top: 1.9166666666666667\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT5: 0.782608695652174\n",
      "mean_sim: 0.72508614593082\n",
      "mean_top: 2.7222222222222223\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT10: 0.9130434782608695\n",
      "mean_sim: 0.7174119835808164\n",
      "mean_top: 3.2857142857142856\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT3: 0.11214953271028037\n",
      "mean_sim: 0.7492195218801498\n",
      "mean_top: 1.9166666666666667\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT5: 0.16822429906542055\n",
      "mean_sim: 0.72508614593082\n",
      "mean_top: 2.7222222222222223\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT10: 0.19626168224299065\n",
      "mean_sim: 0.7174119835808164\n",
      "mean_top: 3.2857142857142856\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName2,pt_model2,1,pt_model2.window,300,pt_model2.sg,pt_model2.epochs,pt_model2.vocabulary.min_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the huge corpus\n",
      "Total examples: 4621219\n",
      "Model training: pt_ft_d300_fb_legalC0_w10_d300_sg1_epochs5_mc1\n",
      "Model training: pt_ft_d300_fb_legalC0_w10_d300_sg1_epochs5_mc1\n",
      "Model trained: pt_ft_d300_fb_legalC0_w10_d300_sg1_epochs5_mc1\n",
      "Fasttext training time: 971.9184100627899\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC0_w10_d300_sg1_epochs5_mc1\\pt_ft_d300_fb_legalC0_w10_d300_sg1_epochs5_mc1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC0_w10_d300_sg1_epochs5_mc1\\pt_ft_d300_fb_legalC0_w10_d300_sg1_epochs5_mc1.model\n",
      "Model saved: pt_ft_d300_fb_legalC0_w10_d300_sg1_epochs5_mc1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT3: 0.6521739130434783\n",
      "mean_sim: 0.7284098585446676\n",
      "mean_top: 2.1333333333333333\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT5: 0.8260869565217391\n",
      "mean_sim: 0.7189462843694185\n",
      "mean_top: 2.526315789473684\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT10: 0.9130434782608695\n",
      "mean_sim: 0.7082696585428148\n",
      "mean_top: 2.9523809523809526\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT3: 0.14018691588785046\n",
      "mean_sim: 0.7284098585446676\n",
      "mean_top: 2.1333333333333333\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT5: 0.17757009345794392\n",
      "mean_sim: 0.7189462843694185\n",
      "mean_top: 2.526315789473684\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT10: 0.19626168224299065\n",
      "mean_sim: 0.7082696585428148\n",
      "mean_top: 2.9523809523809526\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName2,pt_model2,0,10,300,1,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the huge corpus\n",
      "Total examples: 4621219\n",
      "Model training: pt_ft_d300_fb_legalC0_w15_d300_sg1_epochs5_mc1\n",
      "Model training: pt_ft_d300_fb_legalC0_w15_d300_sg1_epochs5_mc1\n",
      "Model trained: pt_ft_d300_fb_legalC0_w15_d300_sg1_epochs5_mc1\n",
      "Fasttext training time: 960.4220600128174\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC0_w15_d300_sg1_epochs5_mc1\\pt_ft_d300_fb_legalC0_w15_d300_sg1_epochs5_mc1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC0_w15_d300_sg1_epochs5_mc1\\pt_ft_d300_fb_legalC0_w15_d300_sg1_epochs5_mc1.model\n",
      "Model saved: pt_ft_d300_fb_legalC0_w15_d300_sg1_epochs5_mc1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT3: 0.6521739130434783\n",
      "mean_sim: 0.7141187349955241\n",
      "mean_top: 2.1333333333333333\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT5: 0.782608695652174\n",
      "mean_sim: 0.702089766661326\n",
      "mean_top: 2.5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT10: 0.9130434782608695\n",
      "mean_sim: 0.6919786958467393\n",
      "mean_top: 3.142857142857143\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT3: 0.14018691588785046\n",
      "mean_sim: 0.7141187349955241\n",
      "mean_top: 2.1333333333333333\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT5: 0.16822429906542055\n",
      "mean_sim: 0.702089766661326\n",
      "mean_top: 2.5\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT10: 0.19626168224299065\n",
      "mean_sim: 0.6919786958467393\n",
      "mean_top: 3.142857142857143\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName2,pt_model2,0,15,300,1,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the small corpus\n",
      "Total examples: 924240\n",
      "Model training: pt_ft_d300_fb_legalC1_w15_d300_sg1_epochs5_mc1\n",
      "Model training: pt_ft_d300_fb_legalC1_w15_d300_sg1_epochs5_mc1\n",
      "Model trained: pt_ft_d300_fb_legalC1_w15_d300_sg1_epochs5_mc1\n",
      "Fasttext training time: 253.43415904045105\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC1_w15_d300_sg1_epochs5_mc1\\pt_ft_d300_fb_legalC1_w15_d300_sg1_epochs5_mc1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC1_w15_d300_sg1_epochs5_mc1\\pt_ft_d300_fb_legalC1_w15_d300_sg1_epochs5_mc1.model\n",
      "Model saved: pt_ft_d300_fb_legalC1_w15_d300_sg1_epochs5_mc1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.21739130434782608\n",
      "evalScoreT3: 0.6086956521739131\n",
      "mean_sim: 0.696237998349326\n",
      "mean_top: 2.0714285714285716\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.21739130434782608\n",
      "evalScoreT5: 0.782608695652174\n",
      "mean_sim: 0.68500859869851\n",
      "mean_top: 2.611111111111111\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.21739130434782608\n",
      "evalScoreT10: 0.9130434782608695\n",
      "mean_sim: 0.6730370408012754\n",
      "mean_top: 3.238095238095238\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.04672897196261682\n",
      "evalScoreT3: 0.1308411214953271\n",
      "mean_sim: 0.696237998349326\n",
      "mean_top: 2.0714285714285716\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.04672897196261682\n",
      "evalScoreT5: 0.16822429906542055\n",
      "mean_sim: 0.68500859869851\n",
      "mean_top: 2.611111111111111\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.04672897196261682\n",
      "evalScoreT10: 0.19626168224299065\n",
      "mean_sim: 0.6730370408012754\n",
      "mean_top: 3.238095238095238\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName2,pt_model2,1,15,300,1,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the small corpus\n",
      "Total examples: 924240\n",
      "Model training: pt_ft_d300_fb_legalC1_w10_d300_sg1_epochs5_mc1\n",
      "Model training: pt_ft_d300_fb_legalC1_w10_d300_sg1_epochs5_mc1\n",
      "Model trained: pt_ft_d300_fb_legalC1_w10_d300_sg1_epochs5_mc1\n",
      "Fasttext training time: 242.28371787071228\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC1_w10_d300_sg1_epochs5_mc1\\pt_ft_d300_fb_legalC1_w10_d300_sg1_epochs5_mc1.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC1_w10_d300_sg1_epochs5_mc1\\pt_ft_d300_fb_legalC1_w10_d300_sg1_epochs5_mc1.model\n",
      "Model saved: pt_ft_d300_fb_legalC1_w10_d300_sg1_epochs5_mc1\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT3: 0.4782608695652174\n",
      "mean_sim: 0.70012413371693\n",
      "mean_top: 1.9090909090909092\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT5: 0.782608695652174\n",
      "mean_sim: 0.674173073636161\n",
      "mean_top: 2.7777777777777777\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT10: 0.9130434782608695\n",
      "mean_sim: 0.6619201188995725\n",
      "mean_top: 3.3333333333333335\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT3: 0.102803738317757\n",
      "mean_sim: 0.70012413371693\n",
      "mean_top: 1.9090909090909092\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT5: 0.16822429906542055\n",
      "mean_sim: 0.674173073636161\n",
      "mean_top: 2.7777777777777777\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT10: 0.19626168224299065\n",
      "mean_sim: 0.6619201188995725\n",
      "mean_top: 3.3333333333333335\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName2,pt_model2,1,10,300,1,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the small corpus\n",
      "Total examples: 924240\n",
      "Model training: pt_ft_d300_fb_legalC1_w15_d300_sg1_epochs5_mc152\n",
      "Model training: pt_ft_d300_fb_legalC1_w15_d300_sg1_epochs5_mc152\n",
      "Model trained: pt_ft_d300_fb_legalC1_w15_d300_sg1_epochs5_mc152\n",
      "Fasttext training time: 263.0514979362488\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC1_w15_d300_sg1_epochs5_mc152\\pt_ft_d300_fb_legalC1_w15_d300_sg1_epochs5_mc152.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC1_w15_d300_sg1_epochs5_mc152\\pt_ft_d300_fb_legalC1_w15_d300_sg1_epochs5_mc152.model\n",
      "Model saved: pt_ft_d300_fb_legalC1_w15_d300_sg1_epochs5_mc152\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT3: 0.5217391304347826\n",
      "mean_sim: 0.6797606348991394\n",
      "mean_top: 2.1666666666666665\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT5: 0.782608695652174\n",
      "mean_sim: 0.6609099838468764\n",
      "mean_top: 2.8333333333333335\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT10: 0.9130434782608695\n",
      "mean_sim: 0.6493556868462336\n",
      "mean_top: 3.3333333333333335\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT3: 0.11214953271028037\n",
      "mean_sim: 0.6797606348991394\n",
      "mean_top: 2.1666666666666665\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT5: 0.16822429906542055\n",
      "mean_sim: 0.6609099838468764\n",
      "mean_top: 2.8333333333333335\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT10: 0.19626168224299065\n",
      "mean_sim: 0.6493556868462336\n",
      "mean_top: 3.3333333333333335\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName2,pt_model2,1,15,300,1,5,152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the small corpus\n",
      "Total examples: 924240\n",
      "Model training: pt_ft_d300_fb_legalC1_w10_d300_sg1_epochs5_mc152\n",
      "Model training: pt_ft_d300_fb_legalC1_w10_d300_sg1_epochs5_mc152\n",
      "Model trained: pt_ft_d300_fb_legalC1_w10_d300_sg1_epochs5_mc152\n",
      "Fasttext training time: 241.6328022480011\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC1_w10_d300_sg1_epochs5_mc152\\pt_ft_d300_fb_legalC1_w10_d300_sg1_epochs5_mc152.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC1_w10_d300_sg1_epochs5_mc152\\pt_ft_d300_fb_legalC1_w10_d300_sg1_epochs5_mc152.model\n",
      "Model saved: pt_ft_d300_fb_legalC1_w10_d300_sg1_epochs5_mc152\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT3: 0.5217391304347826\n",
      "mean_sim: 0.6742906719446182\n",
      "mean_top: 2.25\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT5: 0.8260869565217391\n",
      "mean_sim: 0.6555494917066473\n",
      "mean_top: 3.0\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT10: 0.9130434782608695\n",
      "mean_sim: 0.6433711137090411\n",
      "mean_top: 3.380952380952381\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT3: 0.11214953271028037\n",
      "mean_sim: 0.6742906719446182\n",
      "mean_top: 2.25\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT5: 0.17757009345794392\n",
      "mean_sim: 0.6555494917066473\n",
      "mean_top: 3.0\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT10: 0.19626168224299065\n",
      "mean_sim: 0.6433711137090411\n",
      "mean_top: 3.380952380952381\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName2,pt_model2,1,10,300,1,5,152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the huge corpus\n",
      "Total examples: 4621219\n",
      "Model training: pt_ft_d300_fb_legalC0_w10_d300_sg1_epochs5_mc152\n",
      "Model training: pt_ft_d300_fb_legalC0_w10_d300_sg1_epochs5_mc152\n",
      "Model trained: pt_ft_d300_fb_legalC0_w10_d300_sg1_epochs5_mc152\n",
      "Fasttext training time: 1031.3582170009613\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC0_w10_d300_sg1_epochs5_mc152\\pt_ft_d300_fb_legalC0_w10_d300_sg1_epochs5_mc152.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC0_w10_d300_sg1_epochs5_mc152\\pt_ft_d300_fb_legalC0_w10_d300_sg1_epochs5_mc152.model\n",
      "Model saved: pt_ft_d300_fb_legalC0_w10_d300_sg1_epochs5_mc152\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT3: 0.5652173913043478\n",
      "mean_sim: 0.6783050711338336\n",
      "mean_top: 2.230769230769231\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT5: 0.782608695652174\n",
      "mean_sim: 0.6622749070326487\n",
      "mean_top: 2.888888888888889\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT10: 0.9130434782608695\n",
      "mean_sim: 0.6518576854751224\n",
      "mean_top: 3.4285714285714284\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT3: 0.12149532710280374\n",
      "mean_sim: 0.6783050711338336\n",
      "mean_top: 2.230769230769231\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT5: 0.16822429906542055\n",
      "mean_sim: 0.6622749070326487\n",
      "mean_top: 2.888888888888889\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT10: 0.19626168224299065\n",
      "mean_sim: 0.6518576854751224\n",
      "mean_top: 3.4285714285714284\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName2,pt_model2,0,10,300,1,5,152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the huge corpus\n",
      "Total examples: 4621219\n",
      "Model training: pt_ft_d300_fb_legalC0_w15_d300_sg1_epochs5_mc152\n",
      "Model training: pt_ft_d300_fb_legalC0_w15_d300_sg1_epochs5_mc152\n",
      "Model trained: pt_ft_d300_fb_legalC0_w15_d300_sg1_epochs5_mc152\n",
      "Fasttext training time: 1081.864176273346\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC0_w15_d300_sg1_epochs5_mc152\\pt_ft_d300_fb_legalC0_w15_d300_sg1_epochs5_mc152.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC0_w15_d300_sg1_epochs5_mc152\\pt_ft_d300_fb_legalC0_w15_d300_sg1_epochs5_mc152.model\n",
      "Model saved: pt_ft_d300_fb_legalC0_w15_d300_sg1_epochs5_mc152\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT3: 0.6956521739130435\n",
      "mean_sim: 0.6709863990545273\n",
      "mean_top: 2.3125\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT5: 0.8260869565217391\n",
      "mean_sim: 0.6578615997966967\n",
      "mean_top: 2.736842105263158\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.17391304347826086\n",
      "evalScoreT10: 0.9130434782608695\n",
      "mean_sim: 0.6462348642803374\n",
      "mean_top: 3.1904761904761907\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT3: 0.14953271028037382\n",
      "mean_sim: 0.6709863990545273\n",
      "mean_top: 2.3125\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT5: 0.17757009345794392\n",
      "mean_sim: 0.6578615997966967\n",
      "mean_top: 2.736842105263158\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.037383177570093455\n",
      "evalScoreT10: 0.19626168224299065\n",
      "mean_sim: 0.6462348642803374\n",
      "mean_top: 3.1904761904761907\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName2,pt_model2,0,15,300,1,5,152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the huge corpus\n",
      "Total examples: 4621219\n",
      "Model training: pt_ft_d300_fb_legalC0_w20_d300_sg1_epochs5_mc152\n",
      "Model training: pt_ft_d300_fb_legalC0_w20_d300_sg1_epochs5_mc152\n",
      "Model trained: pt_ft_d300_fb_legalC0_w20_d300_sg1_epochs5_mc152\n",
      "Fasttext training time: 1136.179063796997\n",
      "D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC0_w20_d300_sg1_epochs5_mc152\\pt_ft_d300_fb_legalC0_w20_d300_sg1_epochs5_mc152.model not existed, creating...\n",
      "Saving model to D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_fb_legalC0_w20_d300_sg1_epochs5_mc152\\pt_ft_d300_fb_legalC0_w20_d300_sg1_epochs5_mc152.model\n",
      "Model saved: pt_ft_d300_fb_legalC0_w20_d300_sg1_epochs5_mc152\n",
      "evaluating T3\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.13043478260869565\n",
      "evalScoreT3: 0.6521739130434783\n",
      "mean_sim: 0.6518864909807841\n",
      "mean_top: 2.4\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.13043478260869565\n",
      "evalScoreT5: 0.7391304347826086\n",
      "mean_sim: 0.6471281928174636\n",
      "mean_top: 2.6470588235294117\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:False\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.13043478260869565\n",
      "evalScoreT10: 0.9130434782608695\n",
      "mean_sim: 0.628005006483623\n",
      "mean_top: 3.4761904761904763\n",
      "evaluating done.\n",
      "evaluating T3\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.028037383177570093\n",
      "evalScoreT3: 0.14018691588785046\n",
      "mean_sim: 0.6518864909807841\n",
      "mean_top: 2.4\n",
      "evaluating done.\n",
      "evaluating T5\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.028037383177570093\n",
      "evalScoreT5: 0.1588785046728972\n",
      "mean_sim: 0.6471281928174636\n",
      "mean_top: 2.6470588235294117\n",
      "evaluating done.\n",
      "evaluating T10\n",
      "d4u:True\n",
      "Quadruplets with out-of-vocabulary words:  78.50467289719626\n",
      "evalScoreT1:  0.028037383177570093\n",
      "evalScoreT10: 0.19626168224299065\n",
      "mean_sim: 0.628005006483623\n",
      "mean_top: 3.4761904761904763\n",
      "evaluating done.\n"
     ]
    }
   ],
   "source": [
    "ft_c_train_eval(modelName2,pt_model2,0,20,300,1,5,152)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. !!!先运行完以下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText \n",
    "from gensim.test.utils import datapath\n",
    "import time\n",
    "from gensim.test.utils import get_tmpfile\n",
    "import logging\n",
    "from gensim import utils\n",
    "from itertools import chain\n",
    "from gensim.utils import tokenize\n",
    "import smart_open\n",
    "import os\n",
    "#from gensim.models.wrappers import FastText\n",
    "from gensim.models import KeyedVectors \n",
    "#from gensim importmodels\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogies = datapath(os.getcwd()+'\\\\german-legal-analogies.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.models import FastText "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## continue training prtrained models on legal corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the small legal corpus\n",
    "class MyIterSmall(object):\n",
    "    def __iter__(self):\n",
    "        path = datapath(os.getcwd()+'\\\\German_legal_corpora\\\\cleaned-small-legal-corpus.txt')\n",
    "        with smart_open.smart_open(path, 'r', encoding='utf-8') as fin:\n",
    "            for line in fin:\n",
    "                yield list(tokenize(line))\n",
    "#open the huge legal corpus\n",
    "class MyIterHuge(object):\n",
    "    def __iter__(self):\n",
    "        path = datapath(os.getcwd()+'\\\\German_legal_corpora\\\\cleaned-huge-legal-corpus.txt')\n",
    "        with smart_open.smart_open(path, 'r', encoding='utf-8') as fin:\n",
    "            for line in fin:\n",
    "                yield list(tokenize(line))\n",
    "class MyIterTest(object):\n",
    "    def __iter__(self):\n",
    "        path = datapath(os.getcwd()+'\\\\German_legal_corpora\\\\test-huge.txt')\n",
    "        with smart_open.smart_open(path, 'r', encoding='utf-8') as fin:\n",
    "            for line in fin:\n",
    "                yield list(tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fasttext(small,window,size,sg):\n",
    "    modelName='ft_s'+str(small)+'_w'+str(window)+'_d' +str(size)+'_sg' +str(sg)\n",
    "    model = FastText(size=size, window=window, min_count=1,sg=sg,min_n=3,max_n=6,negative=5,word_ngrams=1)#?\n",
    "    print(\"Reading corpus\"+str(small)+\"...\")\n",
    "    if(small==1):\n",
    "        print(\"Reading the small corpus\")\n",
    "        model.build_vocab(sentences=MyIterSmall())\n",
    "    else:  \n",
    "        print(\"Reading the huge corpus\")\n",
    "        model.build_vocab(sentences=MyIterHuge())\n",
    "        \n",
    "    total_examples = model.corpus_count\n",
    "    \n",
    "    #train\n",
    "    print(\"Model training: \"+modelName)\n",
    "    start = time.time()\n",
    "    if(small==1):\n",
    "        model.train(sentences=MyIterSmall(), total_examples=total_examples, epochs=5)\n",
    "    else: model.train(sentences=MyIterHuge(), total_examples=total_examples, epochs=5)\n",
    "        \n",
    "    \n",
    "    print(\"Model trained: \"+modelName)\n",
    "    print(\"Fasttext training time: \"+str(time.time()-start))\n",
    "    \n",
    "    return modelName,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_train_fasttext(modelName, model,small,window,size,sg,epochs,min_count):\n",
    "    if(small==1):\n",
    "        print(\"Reading the small corpus\")\n",
    "        model.build_vocab(sentences=MyIterSmall(),update=True)\n",
    "    else:  \n",
    "        print(\"Reading the huge corpus\")\n",
    "        model.build_vocab(sentences=MyIterHuge(),update=True)\n",
    "        \n",
    "    \n",
    "    \n",
    "    total_examples = model.corpus_count\n",
    "    print(\"Total examples: \"+  str(total_examples))\n",
    "    \n",
    "    new_modelName=modelName+\"_legalC\"+str(small)+'_w'+str(window)+'_d' +str(size)+'_sg' +str(sg)+'_epochs' +str(epochs)+'_mc' +str(min_count)\n",
    "    print(\"Model training: \"+new_modelName)\n",
    "    \n",
    "    start = time.time()\n",
    "    print(\"Model training: \"+new_modelName)\n",
    "    if(small==1):\n",
    "        model.train(sentences=MyIterSmall(), total_examples=total_examples,window=window,size=size,sg=sg,epochs=epochs,min_count=min_count)\n",
    "    else: model.train(sentences=MyIterHuge(), total_examples=total_examples,window=window,size=size,sg=sg,epochs=epochs,min_count=min_count)\n",
    " \n",
    "    print(\"Model trained: \"+new_modelName)\n",
    "    print(\"Fasttext training time: \"+str(time.time()-start))\n",
    "      \n",
    "    return new_modelName,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    #print(directory)\n",
    "    if not os.path.exists(directory):\n",
    "        print(file_path+\" not existed, creating...\")\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(modelName,model):\n",
    "    fnameS=os.getcwd()+\"\\\\WEs\\\\ft_pt_legalC\\\\\"+modelName+\"\\\\\"+modelName+\".model\"\n",
    "    ensure_dir(fnameS)\n",
    "    fname = get_tmpfile(fnameS)\n",
    "    print(\"Saving model to \"+fnameS)\n",
    "    \n",
    "    model.save(fname)\n",
    "    model.wv.save_word2vec_format(fnameS[:-5]+\"vec\", binary=False)\n",
    "    print(\"Model saved: \"+modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(n):\n",
    "    \n",
    "    fnameS=os.getcwd()+\"\\\\WEs\\\\ft_pt_legalC\\\\\"+n+\"\\\\\"+n+\".model\"\n",
    "    \n",
    "    fname = get_tmpfile(fnameS)\n",
    "    print(\"Loading model from \"+fnameS)\n",
    "    model = FastText.load(fname)\n",
    "    print(\"Model loaded: \"+n)\n",
    "    return n,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_c_train_eval(modelName, basemodel,small,window,size,sg,epochs,min_count):\n",
    "    modelName,model=continue_train_fasttext(modelName, basemodel,small,window,size,sg,epochs,min_count)\n",
    "#save trained model\n",
    "    save_model(modelName,model)\n",
    "#eval\n",
    "    evaluate_word_analogies2(model.wv,modelName,3,analogies)\n",
    "    evaluate_word_analogies2(model.wv,modelName,5,analogies)\n",
    "    evaluate_word_analogies2(model.wv,modelName,10,analogies)\n",
    "    #evaluate_word_analogies2(model.wv, modelName,3,analogies,dummy4unknown=True)\n",
    "    #evaluate_word_analogies2(model.wv, modelName,5,analogies,dummy4unknown=True)\n",
    "    #evaluate_word_analogies2(model.wv, modelName,10,analogies,dummy4unknown=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_train_eval(modelName,model,newSentences,small):\n",
    "    #load pretrained models\n",
    "    #print(\"Loading the pretrained model\")\n",
    "    #model = FastText.load_fasttext_format(modelPath,full_model=True)\n",
    "    #print(\"Loading done\")\n",
    "    #train\n",
    "    modelName,model=continue_train_fasttext(modelName, model,newSentences,small)\n",
    "    #save trained model\n",
    "    save_model(modelName,model)\n",
    "    #eval\n",
    "    evaluate_word_analogies2(model.wv,modelName,3,analogies)\n",
    "    evaluate_word_analogies2(model.wv,modelName,5,analogies)\n",
    "    evaluate_word_analogies2(model.wv,modelName,10,analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_load_eval(modelName,analogies,small,d4u=False):    \n",
    "    #load trained model\n",
    "    n=modelName+\"_legalC\"+str(small)+'_w'+str(window)+'_d' +str(size)+'_sg' +str(sg)+'_epochs' +str(epochs)+'_mc' +str(min_count)\n",
    "    modelName,model=load_model(n)\n",
    "    #eval\n",
    "    if not (d4u):\n",
    "        evaluate_word_analogies2(model.wv, n,3,analogies)\n",
    "        evaluate_word_analogies2(model.wv, n,5,analogies)\n",
    "        evaluate_word_analogies2(model.wv, n,10,analogies)\n",
    "    else:\n",
    "        evaluate_word_analogies2(model.wv, n+\"_d4u\",3,analogies,dummy4unknown=True)\n",
    "        evaluate_word_analogies2(model.wv, n+\"_d4u\",5,analogies,dummy4unknown=True)\n",
    "        evaluate_word_analogies2(model.wv, n+\"_d4u\",10,analogies,dummy4unknown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_handler(modelName,topn):\n",
    "\n",
    "    logName = \"evalLogs\\ \"+ modelName +\"_evalT\"+str(topn)+\".log\"\n",
    "    fhandler = logging.FileHandler(logName, 'w',encoding=\"UTF-8\")\n",
    "    \n",
    "    # create formatter and add it to the handler\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fhandler.setFormatter(formatter)\n",
    "    return fhandler\n",
    "    \n",
    "def setup_logger(name, modelName,topn, level=logging.DEBUG):\n",
    "\n",
    "    handler = setup_handler(modelName,topn) \n",
    "    \n",
    "    logger = logging.getLogger(name +\"_evalT\"+str(topn))\n",
    "    logger.setLevel(level)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    return logger   \n",
    "\n",
    "\n",
    "def evaluate_word_analogies2(self, modelName,topn,analogies, restrict_vocab=300000, case_insensitive=False, dummy4unknown=False):\n",
    "        \"\"\"Compute performance of the model on an analogy test set.\n",
    "\n",
    "        This is modern variant of :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.accuracy`, see\n",
    "        `discussion on GitHub #1935 <https://github.com/RaRe-Technologies/gensim/pull/1935>`_.\n",
    "\n",
    "        The accuracy is reported (printed to log and returned as a score) for each section separately,\n",
    "        plus there's one aggregate summary at the end.\n",
    "\n",
    "        This method corresponds to the `compute-accuracy` script of the original C word2vec.\n",
    "        See also `Analogy (State of the art) <https://aclweb.org/aclwiki/Analogy_(State_of_the_art)>`_.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        analogies : str\n",
    "            Path to file, where lines are 4-tuples of words, split into sections by \": SECTION NAME\" lines.\n",
    "            See `gensim/test/test_data/questions-words.txt` as example.\n",
    "        restrict_vocab : int, optional\n",
    "            Ignore all 4-tuples containing a word not in the first `restrict_vocab` words.\n",
    "            This may be meaningful if you've sorted the model vocabulary by descending frequency (which is standard\n",
    "            in modern word embedding models).\n",
    "        case_insensitive : bool, optional\n",
    "            If True - convert all words to their uppercase form before evaluating the performance.\n",
    "            Useful to handle case-mismatch between training tokens and words in the test set.\n",
    "            In case of multiple case variants of a single word, the vector for the first occurrence\n",
    "            (also the most frequent if vocabulary is sorted) is taken.\n",
    "        dummy4unknown : bool, optional\n",
    "            If True - produce zero accuracies for 4-tuples with out-of-vocabulary words.\n",
    "            Otherwise, these tuples are skipped entirely and not used in the evaluation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "            The overall evaluation score on the entire evaluation set\n",
    "        sections : list of dict of {str : str or list of tuple of (str, str, str, str)}\n",
    "            Results broken down by each section of the evaluation set. Each dict contains the name of the section\n",
    "            under the key 'section', and lists of correctly and incorrectly predicted 4-tuples of words under the\n",
    "            keys 'correct' and 'incorrect'.\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"evaluating T\"+str(topn))\n",
    "        print(\"d4u:\"+str(dummy4unknown))\n",
    "        if(dummy4unknown): modelName=modelName+\"_d4u\"\n",
    "        #get default analogies score\n",
    "        evalScoreT1=self.evaluate_word_analogies(analogies,dummy4unknown=dummy4unknown)[0]\n",
    "        #get logger\n",
    "\n",
    "        logger=setup_logger(modelName,modelName,topn)\n",
    "        \n",
    "\n",
    "        \n",
    "        ok_vocab = [(w, self.vocab[w]) for w in self.index2word[:restrict_vocab]]\n",
    "        ok_vocab = {w.upper(): v for w, v in reversed(ok_vocab)} if case_insensitive else dict(ok_vocab)\n",
    "        oov = 0\n",
    "        logger.info(\"Evaluating word analogies for top %i words in the model on %s\", restrict_vocab, analogies)\n",
    "        sections, section = [], None\n",
    "        quadruplets_no = 0\n",
    "\n",
    "        for line_no, line in enumerate(utils.smart_open(analogies)):\n",
    "            line = utils.to_unicode(line)\n",
    "            if line.startswith(': '):\n",
    "                # a new section starts => store the old section\n",
    "                if section:\n",
    "                    sections.append(section)\n",
    "                    self._log_evaluate_word_analogies(section)\n",
    "                section = {'section': line.lstrip(': ').strip(), 'correct': [], 'incorrect': []}\n",
    "            else:\n",
    "                if not section:\n",
    "                    raise ValueError(\"Missing section header before line #%i in %s\" % (line_no, analogies))\n",
    "                try:\n",
    "                    if case_insensitive:\n",
    "                        a, b, c, expected = [word.upper() for word in line.split()]\n",
    "                    else:\n",
    "                        a, b, c, expected = [word for word in line.split()]\n",
    "                except ValueError:\n",
    "                    logger.info(\"Skipping invalid line #%i in %s\", line_no, analogies)\n",
    "                    continue\n",
    "                quadruplets_no += 1\n",
    "                if a not in ok_vocab or b not in ok_vocab or c not in ok_vocab or expected not in ok_vocab:\n",
    "                    oov += 1\n",
    "                    if dummy4unknown:\n",
    "                        logger.debug('Zero accuracy for line #%d with OOV words: %s', line_no, line.strip())\n",
    "                        section['incorrect'].append((a, b, c, expected))\n",
    "                    else:\n",
    "                        logger.debug(\"Skipping line #%i with OOV words: %s\", line_no, line.strip())\n",
    "                    continue\n",
    "                original_vocab = self.vocab\n",
    "                self.vocab = ok_vocab\n",
    "                ignore = {a, b, c}  # input words to be ignored\n",
    "                predicted = None\n",
    "                logger.info('Start predicting: %s + %s - %s = %s',b, c,a, expected)\n",
    "                # find the most likely prediction using 3CosAdd (vector offset) method\n",
    "                # TODO: implement 3CosMul and set-based methods for solving analogies\n",
    "                #print(\"topn=\"+str(topn))\n",
    "                sims = self.most_similar(positive=[b, c], negative=[a], topn=topn, restrict_vocab=restrict_vocab)\n",
    "                #print(a,b,c,sims)\n",
    "                self.vocab = original_vocab\n",
    "                predicted10=0\n",
    "                topN=1\n",
    "                for element in sims:\n",
    "                    predicted = element[0].upper() if case_insensitive else element[0]\n",
    "                    sim=element[1]\n",
    "                    #print(\"predicted \"+predicted)\n",
    "                    #print(\"expected \"+expected)\n",
    "                    if predicted in ok_vocab and predicted not in ignore:\n",
    "                        if predicted != expected:\n",
    "                            logger.debug(\"%s: expected %s, predicted %s,sim %s,top %i\", line.strip(), expected, predicted,sim,topN)\n",
    "                            topN+=1\n",
    "                        #break\n",
    "                    if predicted == expected:\n",
    "                        logger.info('Expected word found: %s + %s - %s = %s, sim %s, top %i',b, c,a, expected,sim,topN)\n",
    "                        #print(\"!!!\")\n",
    "                        section['correct'].append((a, b, c, expected,predicted,sim,topN))\n",
    "                        predicted10=1\n",
    "                        break\n",
    "                if predicted10==0:\n",
    "                    section['incorrect'].append((a, b, c, expected,predicted))\n",
    "        if section:\n",
    "            # store the last section, too\n",
    "            sections.append(section)\n",
    "            self._log_evaluate_word_analogies(section)\n",
    "\n",
    "        total = {\n",
    "            'section': 'Total accuracy',\n",
    "            'correct': list(chain.from_iterable(s['correct'] for s in sections)),\n",
    "            'incorrect': list(chain.from_iterable(s['incorrect'] for s in sections)),\n",
    "        }\n",
    "        oov_ratio = float(oov) / quadruplets_no * 100\n",
    "        logger.info('Quadruplets with out-of-vocabulary words: %.1f%%', oov_ratio)\n",
    "        print('Quadruplets with out-of-vocabulary words: ', oov_ratio)\n",
    "        if not dummy4unknown:\n",
    "            logger.info(\n",
    "                'NB: analogies containing OOV words were skipped from evaluation! '\n",
    "                'To change this behavior, use \"dummy4unknown=True\"'\n",
    "            )\n",
    "        analogies_score = self._log_evaluate_word_analogies(total)\n",
    "        sections.append(total)\n",
    "        mean_sim,mean_top=correctWord_sim(total)\n",
    "        logger.info('evalScoreT1: %.4f',evalScoreT1)\n",
    "        print('evalScoreT1: ',evalScoreT1)\n",
    "        print('evalScoreT'+str(topn)+\": \"+str(analogies_score))\n",
    "        logger.info('evalScoreT%i: %.4f',topn, analogies_score)\n",
    "        logger.info( 'mean_sim: %.4f', mean_sim)\n",
    "        print( 'mean_sim:', mean_sim)\n",
    "        logger.info('mean_top: %.4f',mean_top)\n",
    "        print('mean_top:',mean_top)\n",
    "        # Return the overall score and the full lists of correct and incorrect analogies\n",
    "        logging.shutdown()\n",
    "        print(\"evaluating done.\")\n",
    "        \n",
    "        return evalScoreT1,mean_sim,mean_top, analogies_score, sections\n",
    "    \n",
    "def correctWord_sim(total):\n",
    "    corrects=total['correct']\n",
    "    sim=[]\n",
    "    top=[]\n",
    "    for c in corrects:\n",
    "        sim.append(c[5])\n",
    "        top.append(c[6])\n",
    "    #print(sim)\n",
    "    if len(sim)!=0: mean_sim=sum(sim)/len(sim)\n",
    "    else: mean_sim=0\n",
    "    if len(top)!=0: mean_top=sum(top)/len(top)\n",
    "    else: mean_top=0\n",
    "    return mean_sim,mean_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from D:\\german_legal_WE\\WEs\\ft_pt_legalC\\pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc152\\pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc152.model\n",
      "Model loaded: pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc152\n"
     ]
    }
   ],
   "source": [
    "name,model=load_model(\"pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc152\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###modelPath:  pt_ft_d300_ky_legalC1_w5_d300_sg1_epochs5_mc152\n",
      "window:  5\n",
      "embed size:  300\n",
      "sg:  1\n",
      "epochs:  5\n",
      "min_count:  152\n",
      "negative sampling:  5\n",
      "min_n: 3\n",
      "max_n: 6\n",
      "Vocabulary sie:  51010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `min_n` (Attribute will be removed in 4.0.0, use wv.min_n instead).\n",
      "  if __name__ == '__main__':\n",
      "D:\\Anaconda\\envs\\RQ\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `max_n` (Attribute will be removed in 4.0.0, use wv.max_n instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "print_basemodel_info(name,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
